{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GaussLayer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/btekgit/GaussianLayer/blob/master/GaussLayer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLV2ztzfHsl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CODE for Gaussian Layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXCGJ9NPH1NK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d4010b3b-943f-4837-d192-645352383488"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Feb 13 19:07:34 2018\n",
        "LAst update Jun 17 2019\n",
        "\n",
        "@author: btek\n",
        "\"\"\"\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras.utils import conv_utils\n",
        "from keras import activations, regularizers, constraints\n",
        "from keras import initializers\n",
        "from keras.engine import InputSpec\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU5r1jH0H5af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def idx_init(shape, dtype='float32'):\n",
        "    idxs = np.zeros((shape[0], shape[1]),dtype)\n",
        "    c = 0\n",
        "    # assumes square filters\n",
        "    print(\"Hereeee\")\n",
        "    wid = np.int(np.sqrt(shape[0]))\n",
        "    hei =np.int(np.sqrt(shape[0]))\n",
        "    f = np.float32\n",
        "    for x in np.arange(wid):  # / (self.incoming_width * 1.0):\n",
        "        for y in np.arange(hei):  # / (self.incoming_height * 1.0):\n",
        "            idxs[c, :] = np.array([x/f(wid), y/f(hei)],dtype)\n",
        "            c += 1\n",
        "\n",
        "    return idxs\n",
        "\n",
        "def cov_init(shape, dtype='float32'):\n",
        "    \n",
        "    cov = np.identity(shape[1], dtype)\n",
        "    # shape [0] must have self.incoming_channels * self.num_filters\n",
        "    cov = np.repeat(cov[np.newaxis], shape[0], axis=0)\n",
        "    \n",
        "    #for t in range(shape[0]):\n",
        "    #    cov[t] = cov[t]\n",
        "    return cov\n",
        "\n",
        "def scale_init(shape, dtype='float32'):\n",
        "    #sc = np.linspace(0.5, 1.6, shape[0]) #best for mnist cluttered\n",
        "    #sc = np.linspace(0.05, 0.1, shape[0],dtype=dtype) #best for mnist cluttered\n",
        "    #sc = 0.05*np.ones(shape[0],dtype=dtype) #best for mnist cluttered\n",
        "    sc = np.linspace(0.1, 0.1, shape[0],dtype=dtype)#tried on fashion mnist with no difference\n",
        "    #sc=np.expand_dims(sc, axis=1)\n",
        "    #sc=np.expand_dims(sc, axis=2)\n",
        "    #print(sc)\n",
        "    return sc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsUuLKvKH8V-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GaussScaler(Layer):\n",
        "    def __init__(self, rank, filters,\n",
        "                 kernel_size,\n",
        "                 strides=1,\n",
        "                 padding='valid',\n",
        "                 data_format=None,\n",
        "                 dilation_rate=1,\n",
        "                 activation=None,\n",
        "                 use_bias=False,\n",
        "                 kernel_regularizer=None,\n",
        "                 gain=1.0,\n",
        "                 output_padding=None,\n",
        "                 **kwargs):\n",
        "        super(GaussScaler, self).__init__(**kwargs)\n",
        "        #def __init__(self, num_filters, kernel_size, incoming_channels=1, **kwargs):\n",
        "        self.rank = rank\n",
        "        self.filters = filters\n",
        "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n",
        "        self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n",
        "        self.padding = conv_utils.normalize_padding(padding)\n",
        "        self.data_format = data_format\n",
        "        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank, 'dilation_rate')\n",
        "        self.activation = activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.input_spec = InputSpec(ndim=self.rank + 2)\n",
        "        self.gain = gain\n",
        "                 \n",
        "        #self.input_shape = input_shape\n",
        "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
        "            kwargs['input_shape'] = (kwargs.pop('input_dim'))\n",
        "        print(kwargs)\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        self.num_filters = filters\n",
        "        #self.incoming_channels = incoming_channels\n",
        "        print(\"HEREERREEE 1\")\n",
        "        \n",
        "        self.output_padding = output_padding\n",
        "        if self.output_padding is not None:\n",
        "            self.output_padding = conv_utils.normalize_tuple(\n",
        "                self.output_padding, 2, 'output_padding')\n",
        "            for stride, out_pad in zip(self.strides, self.output_padding):\n",
        "                if out_pad >= stride:\n",
        "                    raise ValueError('Stride ' + str(self.strides) + ' must be '\n",
        "                                     'greater than output padding ' +str(self.output_padding))\n",
        "                    \n",
        "        super(GaussScaler, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "        if input_shape[channel_axis] is None:\n",
        "            raise ValueError('The channel dimension of the inputs '\n",
        "                             'should be defined. Found `None`.')\n",
        "        input_dim = input_shape[channel_axis]\n",
        "        \n",
        "        self.input_channels = input_dim\n",
        "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "        print(\"kernel shape:\",kernel_shape)\n",
        "\n",
        "        self.bias = None\n",
        "        # Set input spec.\n",
        "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
        "                                    axes={channel_axis: input_dim})\n",
        "        self.built = True\n",
        "        # Create a trainable weight variable for this layer.\n",
        "        \n",
        "        kernel_size = self.kernel_size\n",
        "        # Idxs Init\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        #mu = np.array([kernel_size[0] // 2, kernel_size[1] // 2])\n",
        "        mu = np.array([0.5, 0.5])\n",
        "\n",
        "\n",
        "        # Convert Types\n",
        "        self.mu = mu.astype(dtype='float32')\n",
        "\n",
        "        # Shared Parameters\n",
        "        # below works for only two dimensional cov \n",
        "        #self.cov = self.add_weight(shape=[input_dim*self.filters,2,2], \n",
        "        #                          name=\"cov\", initializer=cov_init, trainable=False)\n",
        "        \n",
        "        \n",
        "        self.cov_scaler = self.add_weight(shape=(self.filters,),\n",
        "                                          name='scaler',initializer=scale_init,\n",
        "                                          trainable=True,\n",
        "                                          constraint= constraints.NonNeg())\n",
        "                                  #constraint=constraints.non_neg())\n",
        "        \n",
        "        #print(\"Self.cov:\",self.cov)\n",
        "        #print(\"Self cov-scaler\",self.cov_scaler)\n",
        "        \n",
        "        # below prepares a meshgrid. \n",
        "        #self.idxs = self.add_weight(shape=[kernel_size[0]*kernel_size[1],2], \n",
        "        #                           name=\"idxs\", initializer=idx_init, trainable=False)\n",
        "        \n",
        "        self.idxs= idx_init(shape=[kernel_size[0]*kernel_size[1],2])\n",
        "        \n",
        "        super(GaussScaler, self).build(input_shape)  # Be sure to call this somewhere!\n",
        "        \n",
        "    \n",
        "    def U(self):\n",
        "  \n",
        "        e1 = (self.idxs - self.mu)\n",
        "        print(\"e1.shape\",e1.shape)\n",
        "        print(\"cov scaler shape\",self.cov_scaler)\n",
        "   \n",
        "        #print(self.cov.shape)\n",
        "        #print(len(tf.unstack(self.cov,axis=0)))\n",
        "        #print( tf.linalg.inv(tf.unstack(self.cov,axis=0)[0]))\n",
        "        # tensorflow does not need scan it does the same op to all covs.\n",
        "        #cov_inv = self.cov\n",
        "        #cov_scaled =self.cov_scaler*self.cov\n",
        "#        cov_scaled = tf.scalar_mul(self.cov_scaler,self.cov)\n",
        "#        print(self.cov.shape, self.cov_scaler.shape )\n",
        "#        cov_scaled = K.batch_dot(self.cov_scaler,self.cov, axes=[1,2])\n",
        "        #cov_inv = tf.linalg.inv(cov_scaled)\n",
        "        #print(\"cov_scaled :\",cov_scaled.shape)\n",
        "        #cov_inv = K.map_fn(lambda x: tf.linalg.inv(x), elems=tf.unstack(self.cov,axis=0))\n",
        "       \n",
        "\n",
        "        #e2 = K.dot(e1, K.transpose(cov_inv))\n",
        "        #ex = K.batch_dot(e2, e1, axes=[[1], [1]])\n",
        "        #result = K.exp(-(1 / 2.0) * ex)\n",
        "\n",
        "        up= K.sum((self.idxs - self.mu)**2, axis=1)\n",
        "        print(\"up.shape\",up.shape)\n",
        "        up = K.expand_dims(up,axis=1,)\n",
        "        print(\"up.shape\",up.shape)\n",
        "        # clipping scaler in range to prevent div by 0 or negative cov. \n",
        "        cov_scaler = K.clip(self.cov_scaler,0.01,5)\n",
        "        #cov_scaler = self.cov_scaler\n",
        "        dwn = 2 * (cov_scaler ** 2)\n",
        "        #scaler = (np.pi*self.cov_scaler**2) * (self.idxs.shape[0])\n",
        "        result = K.exp(-up / dwn)\n",
        "        \n",
        "\n",
        "\n",
        "        # Transpose is super important.\n",
        "        #filter: A 4-D `Tensor` with the same type as `value` and shape\n",
        "        #`[height, width, output_channels, in_channels]`\n",
        "        # we do not care about input channels\n",
        "        \n",
        "        masks = K.reshape(result,(self.kernel_size[0],\n",
        "                                  self.kernel_size[1],\n",
        "                                  self.filters,1))   \n",
        "            \n",
        "        #sum normalization each filter has sum 1\n",
        "        #sums = K.sum(masks**2, axis=(0, 1), keepdims=True)\n",
        "        #print(sums)\n",
        "        gain = K.constant(self.gain, dtype='float32')\n",
        "        #masks /= K.sqrt(K.sum(masks**2, axis=(0, 1),keepdims=True))\n",
        "        #masks /= K.sum(masks, axis=(0, 1),keepdims=True)\n",
        "        masks /= (self.kernel_size[0]*self.kernel_size[1])\n",
        "        \n",
        "        #masks *= (gain*np.sqrt(self.kernel_size[0]*self.kernel_size[1]))\n",
        "        #ums = sums * sums\n",
        "        #print(\"sums shape: \", sums.shape)\n",
        "        \n",
        "        # Sum normalisation\n",
        "        \n",
        "        #masks = masks * (gain/K.sqrt(sums))\n",
        "        #masks = masks * (gain/sums)\n",
        "        #print(\"masks shape\", masks.shape)\n",
        "        #print(\"masks mask\", K.mean(masks))\n",
        "        return masks\n",
        "\n",
        "# =============================================================================\n",
        "#     def call(self, inputs):\n",
        "#         \n",
        "#         print(inputs.shape)\n",
        "#         filters = self.U()\n",
        "#         print(filters.shape)\n",
        "#         #filters /= T.sum(filters, axis=(2, 3)).dimshuffle(0, 1, 'x', 'x')\n",
        "#         # channel_first means tensofrlow\n",
        "#         conved = K.conv2d(inputs, filters, padding=self.padding, strides=self.strides,\n",
        "#                                data_format=self.data_format)\n",
        "#         return conved\n",
        "# =============================================================================\n",
        "        \n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_shape = K.shape(inputs)\n",
        "        batch_size = input_shape[0]\n",
        "        if self.data_format == 'channels_first':\n",
        "          h_axis, w_axis = 2, 3\n",
        "          c_axis= 1\n",
        "          \n",
        "        else:\n",
        "            h_axis, w_axis = 1, 2\n",
        "            c_axis=3\n",
        "            \n",
        "        ##BTEK \n",
        "        kernel = self.U()\n",
        "        in_channels =input_shape[c_axis]\n",
        "        \n",
        "        height, width = input_shape[h_axis], input_shape[w_axis]\n",
        "        kernel_h, kernel_w = self.kernel_size\n",
        "        stride_h, stride_w = self.strides\n",
        "        if self.output_padding is None:\n",
        "            out_pad_h = out_pad_w = None\n",
        "        else:\n",
        "            out_pad_h, out_pad_w = self.output_padding\n",
        "\n",
        "        # Infer the dynamic output shape:\n",
        "        out_height = conv_utils.deconv_length(height,\n",
        "                                              stride_h, kernel_h,\n",
        "                                              self.padding,\n",
        "                                              out_pad_h,\n",
        "                                              self.dilation_rate[0])\n",
        "        out_width = conv_utils.deconv_length(width,\n",
        "                                             stride_w, kernel_w,\n",
        "                                             self.padding,\n",
        "                                             out_pad_w,\n",
        "                                             self.dilation_rate[1])\n",
        "        if self.data_format == 'channels_first':\n",
        "            output_shape = (batch_size, self.filters, out_height, out_width)\n",
        "        else:\n",
        "            output_shape = (batch_size, out_height, out_width, self.filters)\n",
        "\n",
        "        ##BTEK \n",
        "        kernel = self.U()\n",
        "        print(\"kernel shape in output:\",kernel.shape)\n",
        "        print(\"channel axis\")\n",
        "        kernel = K.repeat_elements(kernel, self.input_channels, axis=c_axis)\n",
        "        print(\"kernel reshaped :\",kernel.shape)\n",
        "        outputs = K.conv2d_transpose(\n",
        "            inputs,\n",
        "            kernel,\n",
        "            output_shape,\n",
        "            self.strides,\n",
        "            padding=self.padding,\n",
        "            data_format=self.data_format,\n",
        "            dilation_rate=self.dilation_rate)\n",
        "\n",
        "        if self.use_bias:\n",
        "            outputs = K.bias_add(\n",
        "                outputs,\n",
        "                self.bias,\n",
        "                data_format=self.data_format)\n",
        "\n",
        "        if self.activation is not None:\n",
        "            return self.activation(outputs)\n",
        "        return outputs\n",
        "\n",
        "# =============================================================================\n",
        "#     def compute_output_shape(self, input_shape):\n",
        "#         print(\"shapeeee\")\n",
        "#         if self.data_format == 'channels_last':\n",
        "#             space = input_shape[1:-1]\n",
        "#             new_space = []\n",
        "#             for i in range(len(space)):\n",
        "#                 new_dim = conv_utils.conv_output_length(\n",
        "#                     space[i],\n",
        "#                     self.kernel_size[i],\n",
        "#                     padding=self.padding,\n",
        "#                     stride=self.strides[i],\n",
        "#                     dilation=self.dilation_rate[i])\n",
        "#                 new_space.append(new_dim)\n",
        "#             return (input_shape[0],) + tuple(new_space) + (self.filters,)\n",
        "#         if self.data_format == 'channels_first':\n",
        "#             space = input_shape[2:]\n",
        "#             new_space = []\n",
        "#             for i in range(len(space)):\n",
        "#                 new_dim = conv_utils.conv_output_length(\n",
        "#                     space[i],\n",
        "#                     self.kernel_size[i],\n",
        "#                     padding=self.padding,\n",
        "#                     stride=self.strides[i],\n",
        "#                     dilation=self.dilation_rate[i])\n",
        "#                 new_space.append(new_dim)\n",
        "#             return (input_shape[0], self.filters) + tuple(new_space)\n",
        "# =============================================================================\n",
        "        \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_shape = list(input_shape)\n",
        "        if self.data_format == 'channels_first':\n",
        "            c_axis, h_axis, w_axis = 1, 2, 3\n",
        "        else:\n",
        "            c_axis, h_axis, w_axis = 3, 1, 2\n",
        "\n",
        "        kernel_h, kernel_w = self.kernel_size\n",
        "        stride_h, stride_w = self.strides\n",
        "        if self.output_padding is None:\n",
        "            out_pad_h = out_pad_w = None\n",
        "        else:\n",
        "            out_pad_h, out_pad_w = self.output_padding\n",
        "\n",
        "        output_shape[c_axis] = self.filters\n",
        "        output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis],\n",
        "                                                        stride_h,\n",
        "                                                        kernel_h,\n",
        "                                                        self.padding,\n",
        "                                                        out_pad_h,\n",
        "                                                        self.dilation_rate[0])\n",
        "        output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n",
        "                                                        stride_w,\n",
        "                                                        kernel_w,\n",
        "                                                        self.padding,\n",
        "                                                        out_pad_w,\n",
        "                                                        self.dilation_rate[1])\n",
        "        return tuple(output_shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfRXsUkkIDKk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "979286c1-5176-40e8-a4b5-d15cddde3614"
      },
      "source": [
        "   \n",
        "    import keras\n",
        "    from keras.datasets import mnist\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense, Dropout, Flatten\n",
        "    from keras.layers import Conv2D, MaxPooling2D\n",
        "    from keras.layers import BatchNormalization\n",
        "    from keras.optimizers import SGD\n",
        "    from keras import backend as K\n",
        "    \n",
        "    batch_size = 128\n",
        "    num_classes = 10\n",
        "    epochs = 1\n",
        "    \n",
        "    # input image dimensions\n",
        "    img_rows, img_cols = 28, 28\n",
        "    \n",
        "    # the data, split between train and test sets\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    \n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "        input_shape = (1, img_rows, img_cols)\n",
        "    else:\n",
        "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "        input_shape = (img_rows, img_cols, 1)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    print('x_train shape:', x_train.shape)\n",
        "    print(x_train.shape[0], 'train samples')\n",
        "    print(x_test.shape[0], 'test samples')\n",
        "    \n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "    \n",
        "    model = Sequential()\n",
        "    #=============================================================================\n",
        "    model.add(GaussScaler(rank=2,filters=4,kernel_size=(5,5), \n",
        "                           data_format='channels_last',strides=1,\n",
        "                           padding='same',name='gausslayer', activation='linear',\n",
        "                           input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    #=============================================================================\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                     activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        " \n",
        "    model.add(MaxPooling2D(pool_size=(5, 5)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='softmax'))\n",
        "    \n",
        "    \n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.summary()\n",
        "    \n",
        "    from lr_multiplier import LearningRateMultiplier\n",
        "    \n",
        "    multipliers = {'gausslayer': 0.0}\n",
        "    opt = LearningRateMultiplier(SGD, lr_multipliers=multipliers, \n",
        "                                 lr=0.01, momentum=0.9,decay=0.00)\n",
        "    print(opt)\n",
        "    #opt = SGD(lr=0.01,momentum=0.5)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    plt = True\n",
        "    if plt:\n",
        "        print(\"Plotting kernels before...\")\n",
        "        import matplotlib.pyplot as plt\n",
        "        gauss_layer = model.get_layer('gausslayer')\n",
        "        ws = gauss_layer.get_weights()\n",
        "        print(\"Sigmas before\",ws[0])\n",
        "        u_func = K.function(inputs=[model.input], outputs=[gauss_layer.U()])\n",
        "        output_func = K.function(inputs=[model.input], outputs=[gauss_layer.output])\n",
        "    \n",
        "        U_val=u_func([np.expand_dims(x_test[0], axis=0)])\n",
        "        \n",
        "        print(\"U shape\", U_val[0].shape)\n",
        "        print(\"U max:\", np.max(U_val[0][:,:,:,:]))\n",
        "        num_filt=min(U_val[0].shape[2],12)\n",
        "        fig=plt.figure(figsize=(10,5))\n",
        "        for i in range(num_filt):\n",
        "            ax1=plt.subplot(1, num_filt, i+1)\n",
        "            im = ax1.imshow(np.squeeze(U_val[0][:,:,i,0]))\n",
        "        fig.colorbar(im, ax=ax1)\n",
        "        plt.show()\n",
        "        \n",
        "    \n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_test, y_test))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])\n",
        "    \n",
        "\n",
        "    if plt:\n",
        "        print(\"Plotting kernels after ...\")\n",
        "        \n",
        "        print(\"U max:\", np.max(U_val[0][:,:,:,:]))\n",
        "        import matplotlib.pyplot as plt\n",
        "        ws = gauss_layer.get_weights()\n",
        "        print(\"Sigmas before\",ws[0])\n",
        "        U_val=u_func([np.expand_dims(x_test[2], axis=0)])\n",
        "        \n",
        "        print(\"U shape\", U_val[0].shape)\n",
        "        num_filt=min(U_val[0].shape[2],12)\n",
        "        fig=plt.figure(figsize=(16,5))\n",
        "        for i in range(num_filt):\n",
        "            ax=plt.subplot(1, num_filt, i+1)\n",
        "            im = ax.imshow(np.squeeze(U_val[0][:,:,i,0]))\n",
        "        fig.colorbar(im, ax=ax1)\n",
        "        plt.show()\n",
        "        \n",
        "        \n",
        "        print(\"outputs  ...\")\n",
        "        \n",
        "        n=5\n",
        "        \n",
        "        out_val=output_func([np.expand_dims(x_test[5], axis=0)])\n",
        "        print(\"Outputs shape\", out_val[0].shape)\n",
        "        num_filt=min(out_val[0].shape[3],12)\n",
        "        fig=plt.figure(figsize=(16,10))\n",
        "        ax=plt.subplot(1, num_filt+1, 1)\n",
        "        im = ax.imshow(np.squeeze(x_test[5]))\n",
        "        for i in range(num_filt):\n",
        "            ax=plt.subplot(1, num_filt+1, i+2)\n",
        "            im = ax.imshow(np.squeeze(out_val[0][0,:,:,i]))\n",
        "        fig.colorbar(im, ax=ax)\n",
        "        plt.show()\n",
        "        \n",
        "        print(\"input mean,var,max\",np.mean(x_test[5]),np.var(x_test[5]),np.max(x_test[5]))\n",
        "        print(\"ouput mean,var,max\",np.mean(out_val[0][0,:,:,i]),\n",
        "                                           np.var(out_val[0][0,:,:,i]),\n",
        "                                           np.max(out_val[0][0,:,:,i]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-5bcd70a81744>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    import keras\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4K8pEZzIXOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}