{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GaussLayer-cifar10-Gauss.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/btekgit/GaussianLayer/blob/master/GaussLayer_cifar10_Gauss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLV2ztzfHsl3",
        "colab_type": "code",
        "outputId": "90f83ed8-4e79-4427-b2e6-e8cfaedfeb0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# CODE for Gaussian Layer\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXCGJ9NPH1NK",
        "colab_type": "code",
        "outputId": "0461a5e8-bc2a-4bc5-b557-ee3dd8f7a8ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Feb 13 19:07:34 2018\n",
        "LAst update Jun 17 2019\n",
        "\n",
        "@author: btek\n",
        "\"\"\"\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras.utils import conv_utils\n",
        "from keras import activations, regularizers, constraints\n",
        "from keras import initializers\n",
        "from keras.engine import InputSpec\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from numpy.random import seed\n",
        "seed(42)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU5r1jH0H5af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def idx_init(shape, dtype='float32'):\n",
        "    idxs = np.zeros((shape[0], shape[1]),dtype)\n",
        "    c = 0\n",
        "    # assumes square filters\n",
        "    \n",
        "    wid = np.int(np.sqrt(shape[0]))\n",
        "    hei =np.int(np.sqrt(shape[0]))\n",
        "    f = np.float32\n",
        "    for x in np.arange(wid):  # / (self.incoming_width * 1.0):\n",
        "        for y in np.arange(hei):  # / (self.incoming_height * 1.0):\n",
        "            idxs[c, :] = np.array([x/f(wid-1), y/f(hei-1)],dtype)\n",
        "            c += 1\n",
        "\n",
        "    return idxs\n",
        "\n",
        "def cov_init(shape, dtype='float32'):\n",
        "    \n",
        "    cov = np.identity(shape[1], dtype)\n",
        "    # shape [0] must have self.incoming_channels * self.num_filters\n",
        "    cov = np.repeat(cov[np.newaxis], shape[0], axis=0)\n",
        "    \n",
        "    #for t in range(shape[0]):\n",
        "    #    cov[t] = cov[t]\n",
        "    return cov\n",
        "\n",
        "def scale_init(shape, dtype='float32'):\n",
        "    #sc = np.linspace(0.5, 1.6, shape[0]) #best for mnist cluttered\n",
        "    #sc = np.linspace(0.05, 0.1, shape[0],dtype=dtype) #best for mnist cluttered\n",
        "    #sc = 0.05*np.ones(shape[0],dtype=dtype) #best for mnist cluttered\n",
        "    sc = np.linspace(0.05, 0.1, shape[0],dtype=dtype)#tried on fashion mnist with no difference\n",
        "    #sc=np.expand_dims(sc, axis=1)\n",
        "    #sc=np.expand_dims(sc, axis=2)\n",
        "    #print(sc)\n",
        "    return sc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsUuLKvKH8V-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GaussScaler(Layer):\n",
        "    def __init__(self, rank, filters,\n",
        "                 kernel_size,\n",
        "                 strides=1,\n",
        "                 padding='valid',\n",
        "                 data_format=None,\n",
        "                 dilation_rate=1,\n",
        "                 activation=None,\n",
        "                 use_bias=False,\n",
        "                 kernel_regularizer=None,\n",
        "                 gain=1.0,\n",
        "                 output_padding=None,\n",
        "                 **kwargs):\n",
        "        super(GaussScaler, self).__init__(**kwargs)\n",
        "        #def __init__(self, num_filters, kernel_size, incoming_channels=1, **kwargs):\n",
        "        self.rank = rank\n",
        "        self.filters = filters\n",
        "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n",
        "        self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n",
        "        self.padding = conv_utils.normalize_padding(padding)\n",
        "        self.data_format = data_format\n",
        "        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank, 'dilation_rate')\n",
        "        self.activation = activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.input_spec = InputSpec(ndim=self.rank + 2)\n",
        "        self.gain = gain\n",
        "                 \n",
        "        #self.input_shape = input_shape\n",
        "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
        "            kwargs['input_shape'] = (kwargs.pop('input_dim'))\n",
        "        print(kwargs)\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        self.num_filters = filters\n",
        "        #self.incoming_channels = incoming_channels\n",
        "        \n",
        "        \n",
        "        self.output_padding = output_padding\n",
        "        if self.output_padding is not None:\n",
        "            self.output_padding = conv_utils.normalize_tuple(\n",
        "                self.output_padding, 2, 'output_padding')\n",
        "            for stride, out_pad in zip(self.strides, self.output_padding):\n",
        "                if out_pad >= stride:\n",
        "                    raise ValueError('Stride ' + str(self.strides) + ' must be '\n",
        "                                     'greater than output padding ' +str(self.output_padding))\n",
        "                    \n",
        "        super(GaussScaler, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "        if input_shape[channel_axis] is None:\n",
        "            raise ValueError('The channel dimension of the inputs '\n",
        "                             'should be defined. Found `None`.')\n",
        "        input_dim = input_shape[channel_axis]\n",
        "        \n",
        "        self.input_channels = input_dim\n",
        "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "        print(\"kernel shape:\",kernel_shape)\n",
        "\n",
        "        self.bias = None\n",
        "        # Set input spec.\n",
        "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
        "                                    axes={channel_axis: input_dim})\n",
        "        self.built = True\n",
        "        # Create a trainable weight variable for this layer.\n",
        "        \n",
        "        kernel_size = self.kernel_size\n",
        "        # Idxs Init\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        #mu = np.array([kernel_size[0] // 2, kernel_size[1] // 2])\n",
        "        mu = np.array([0.5, 0.5])\n",
        "\n",
        "\n",
        "        # Convert Types\n",
        "        self.mu = mu.astype(dtype='float32')\n",
        "\n",
        "        # Shared Parameters\n",
        "        # below works for only two dimensional cov \n",
        "        #self.cov = self.add_weight(shape=[input_dim*self.filters,2,2], \n",
        "        #                          name=\"cov\", initializer=cov_init, trainable=False)\n",
        "        \n",
        "        \n",
        "        self.cov_scaler = self.add_weight(shape=(self.filters,),\n",
        "                                          name='scaler',initializer=scale_init,\n",
        "                                          trainable=True,\n",
        "                                          constraint= constraints.NonNeg())\n",
        "                                  #constraint=constraints.non_neg())\n",
        "        \n",
        "        #print(\"Self.cov:\",self.cov)\n",
        "        #print(\"Self cov-scaler\",self.cov_scaler)\n",
        "        \n",
        "        # below prepares a meshgrid. \n",
        "        #self.idxs = self.add_weight(shape=[kernel_size[0]*kernel_size[1],2], \n",
        "        #                           name=\"idxs\", initializer=idx_init, trainable=False)\n",
        "        \n",
        "        self.idxs= idx_init(shape=[kernel_size[0]*kernel_size[1],2])\n",
        "        \n",
        "        super(GaussScaler, self).build(input_shape)  # Be sure to call this somewhere!\n",
        "        \n",
        "    \n",
        "    def U(self):\n",
        "  \n",
        "        e1 = (self.idxs - self.mu)\n",
        "        #print(\"e1.shape\",e1.shape)\n",
        "        #print(\"cov scaler shape\",self.cov_scaler)\n",
        "   \n",
        "        #print(self.cov.shape)\n",
        "        #print(len(tf.unstack(self.cov,axis=0)))\n",
        "        #print( tf.linalg.inv(tf.unstack(self.cov,axis=0)[0]))\n",
        "        # tensorflow does not need scan it does the same op to all covs.\n",
        "        #cov_inv = self.cov\n",
        "        #cov_scaled =self.cov_scaler*self.cov\n",
        "#        cov_scaled = tf.scalar_mul(self.cov_scaler,self.cov)\n",
        "#        print(self.cov.shape, self.cov_scaler.shape )\n",
        "#        cov_scaled = K.batch_dot(self.cov_scaler,self.cov, axes=[1,2])\n",
        "        #cov_inv = tf.linalg.inv(cov_scaled)\n",
        "        #print(\"cov_scaled :\",cov_scaled.shape)\n",
        "        #cov_inv = K.map_fn(lambda x: tf.linalg.inv(x), elems=tf.unstack(self.cov,axis=0))\n",
        "       \n",
        "\n",
        "        #e2 = K.dot(e1, K.transpose(cov_inv))\n",
        "        #ex = K.batch_dot(e2, e1, axes=[[1], [1]])\n",
        "        #result = K.exp(-(1 / 2.0) * ex)\n",
        "\n",
        "        up= K.sum((self.idxs - self.mu)**2, axis=1)\n",
        "        #print(\"up.shape\",up.shape)\n",
        "        up = K.expand_dims(up,axis=1,)\n",
        "        #print(\"up.shape\",up.shape)\n",
        "        # clipping scaler in range to prevent div by 0 or negative cov. \n",
        "        cov_scaler = K.clip(self.cov_scaler,0.01,5)\n",
        "        #cov_scaler = self.cov_scaler\n",
        "        dwn = 2 * (cov_scaler ** 2)\n",
        "        #scaler = (np.pi*self.cov_scaler**2) * (self.idxs.shape[0])\n",
        "        result = K.exp(-up / dwn)\n",
        "        \n",
        "\n",
        "\n",
        "        # Transpose is super important.\n",
        "        #filter: A 4-D `Tensor` with the same type as `value` and shape\n",
        "        #`[height, width, output_channels, in_channels]`\n",
        "        # we do not care about input channels\n",
        "        \n",
        "        masks = K.reshape(result,(self.kernel_size[0],\n",
        "                                  self.kernel_size[1],\n",
        "                                  self.filters,1))   \n",
        "            \n",
        "        #sum normalization each filter has sum 1\n",
        "        #sums = K.sum(masks**2, axis=(0, 1), keepdims=True)\n",
        "        #print(sums)\n",
        "        #gain = K.constant(self.gain, dtype='float32')\n",
        "        masks /= K.sqrt(K.sum(K.square(masks), axis=(0, 1),keepdims=True))\n",
        "        #masks /= K.sum(masks, axis=(0, 1),keepdims=True)\n",
        "        #masks /= (self.kernel_size[0]*self.kernel_size[1])\n",
        "        \n",
        "        #masks *= (gain*np.sqrt(self.kernel_size[0]*self.kernel_size[1]))\n",
        "        #ums = sums * sums\n",
        "        #print(\"sums shape: \", sums.shape)\n",
        "        \n",
        "        # Sum normalisation\n",
        "        \n",
        "        #masks = masks * (gain/K.sqrt(sums))\n",
        "        #masks = masks * (gain/sums)\n",
        "        #print(\"masks shape\", masks.shape)\n",
        "        #print(\"masks mask\", K.mean(masks))\n",
        "        return masks\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_shape = K.shape(inputs)\n",
        "        batch_size = input_shape[0]\n",
        "        if self.data_format == 'channels_first':\n",
        "          h_axis, w_axis = 2, 3\n",
        "          c_axis= 1\n",
        "          \n",
        "        else:\n",
        "            h_axis, w_axis = 1, 2\n",
        "            c_axis=3\n",
        "            \n",
        "        ##BTEK \n",
        "        kernel = self.U()\n",
        "        in_channels =input_shape[c_axis]\n",
        "        \n",
        "        height, width = input_shape[h_axis], input_shape[w_axis]\n",
        "        kernel_h, kernel_w = self.kernel_size\n",
        "        stride_h, stride_w = self.strides\n",
        "        if self.output_padding is None:\n",
        "            out_pad_h = out_pad_w = None\n",
        "        else:\n",
        "            out_pad_h, out_pad_w = self.output_padding\n",
        "\n",
        "        # Infer the dynamic output shape:\n",
        "        out_height = conv_utils.deconv_length(height,\n",
        "                                              stride_h, kernel_h,\n",
        "                                              self.padding,\n",
        "                                              out_pad_h,\n",
        "                                              self.dilation_rate[0])\n",
        "        out_width = conv_utils.deconv_length(width,\n",
        "                                             stride_w, kernel_w,\n",
        "                                             self.padding,\n",
        "                                             out_pad_w,\n",
        "                                             self.dilation_rate[1])\n",
        "        if self.data_format == 'channels_first':\n",
        "            output_shape = (batch_size, self.filters, out_height, out_width)\n",
        "        else:\n",
        "            output_shape = (batch_size, out_height, out_width, self.filters)\n",
        "\n",
        "        ##BTEK \n",
        "        kernel = self.U()\n",
        "        print(\"kernel shape in output:\",kernel.shape)\n",
        "        print(\"channel axis\")\n",
        "        kernel = K.repeat_elements(kernel, self.input_channels, axis=c_axis)\n",
        "        print(\"kernel reshaped :\",kernel.shape)\n",
        "        #---------------------------------------------------------------------\n",
        "        outputs = K.conv2d_transpose(\n",
        "            inputs,\n",
        "            kernel,\n",
        "            output_shape,\n",
        "            self.strides,\n",
        "            padding=self.padding,\n",
        "            data_format=self.data_format,\n",
        "            dilation_rate=self.dilation_rate)\n",
        "\n",
        "        if self.use_bias:\n",
        "            outputs = K.bias_add(\n",
        "                outputs,\n",
        "                self.bias,\n",
        "                data_format=self.data_format)\n",
        "\n",
        "        if self.activation is not None:\n",
        "            return self.activation(outputs)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "        \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_shape = list(input_shape)\n",
        "        if self.data_format == 'channels_first':\n",
        "            c_axis, h_axis, w_axis = 1, 2, 3\n",
        "        else:\n",
        "            c_axis, h_axis, w_axis = 3, 1, 2\n",
        "\n",
        "        kernel_h, kernel_w = self.kernel_size\n",
        "        stride_h, stride_w = self.strides\n",
        "        if self.output_padding is None:\n",
        "            out_pad_h = out_pad_w = None\n",
        "        else:\n",
        "            out_pad_h, out_pad_w = self.output_padding\n",
        "\n",
        "        output_shape[c_axis] = self.filters\n",
        "        output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis],\n",
        "                                                        stride_h,\n",
        "                                                        kernel_h,\n",
        "                                                        self.padding,\n",
        "                                                        out_pad_h,\n",
        "                                                        self.dilation_rate[0])\n",
        "        output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n",
        "                                                        stride_w,\n",
        "                                                        kernel_w,\n",
        "                                                        self.padding,\n",
        "                                                        out_pad_w,\n",
        "                                                        self.dilation_rate[1])\n",
        "        return tuple(output_shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfRXsUkkIDKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input,Lambda, Concatenate\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4K8pEZzIXOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # LOAD DATA\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDSdnMlILOk8",
        "colab_type": "code",
        "outputId": "8fd4f83c-68e4-40fb-ff93-6999e142587d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "num_classes = 10\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 32, 32\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
        "    input_shape = (img_rows, img_cols, 3)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4BQMgF7LVHV",
        "colab_type": "text"
      },
      "source": [
        "CREATE THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBxSz02zLPAd",
        "colab_type": "code",
        "outputId": "0658b3c8-9071-4b96-ca01-234b4c3aca37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1635
        }
      },
      "source": [
        "# CREATE THE MODEL\n",
        "nGauss = 4\n",
        "n_input_channels=3\n",
        "node_in  = Input(shape=input_shape)\n",
        "if nGauss>0:\n",
        "    if n_input_channels==3:\n",
        "        pool_channels=[]\n",
        "        for i in range(n_input_channels):\n",
        "            # separate channels\n",
        "            # use input directly at least in one channel\n",
        "            g_c= Lambda(lambda x: K.expand_dims(x[:,:,:,i],axis=3), name='ChannelSeparator'+str(i))(node_in)\n",
        "            gauss_pooled = GaussScaler(rank=2,filters=4,kernel_size=(5,5), \n",
        "                                 input_shape=input_shape, \n",
        "                                 padding='same',gain=1.0, name='gausslayer'+str(i))(g_c)\n",
        "\n",
        "            pool_channels.append(gauss_pooled)\n",
        "        node_pool1 = Concatenate(name='merge',axis=-1)(pool_channels)\n",
        "        node_conv=Conv2D(32, kernel_size=(3, 3),activation='relu')(node_pool1)\n",
        "    \n",
        "    else:\n",
        "        #=============================================================================\n",
        "        gs=GaussScaler(rank=2,filters=nGauss,kernel_size=(5,5), \n",
        "                         data_format='channels_last',strides=1,\n",
        "                         padding='same',name='gausslayer', activation='linear',\n",
        "                         input_shape=input_shape)(node_in)\n",
        "        #gs= BatchNormalization()(gs)\n",
        "        node_conv=Conv2D(32, kernel_size=(3, 3),activation='relu')(gs)\n",
        "#=============================================================================\n",
        "else:\n",
        "    node_conv=Conv2D(32, kernel_size=(3, 3),\n",
        "                     activation='relu',input_shape=input_shape)(node_in)\n",
        "  \n",
        "node=Conv2D(32, (3, 3),activation='relu')(node_conv)\n",
        "node=BatchNormalization()(node)\n",
        "\n",
        "node=Conv2D(64, (3, 3),activation='relu',padding='same')(node)\n",
        "node=BatchNormalization()(node)\n",
        "node=MaxPooling2D(pool_size=(2, 2))(node)\n",
        "node=Dropout(0.25)(node)\n",
        "\n",
        "node=Conv2D(96, (3, 3),activation='relu',padding='same')(node)\n",
        "node=BatchNormalization()(node)\n",
        "\n",
        "node=MaxPooling2D(pool_size=(2, 2))(node)\n",
        "node=Dropout(0.25)(node)\n",
        "\n",
        "node=Flatten()(node)\n",
        "node=Dense(512)(node)\n",
        "node=Activation('relu')(node)\n",
        "node=Dropout(0.5)(node)\n",
        "node=Dense(num_classes)(node)\n",
        "pred=Activation('softmax')(node)\n",
        "\n",
        "model = Model(inputs=node_in, outputs=[pred])\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0618 08:02:14.558362 139788871563136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0618 08:02:14.561628 139788871563136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'input_shape': (32, 32, 3), 'name': 'gausslayer0'}\n",
            "kernel shape: (5, 5, 1, 4)\n",
            "kernel shape in output: (5, 5, 4, 1)\n",
            "channel axis\n",
            "kernel reshaped : (5, 5, 4, 1)\n",
            "{'input_shape': (32, 32, 3), 'name': 'gausslayer1'}\n",
            "kernel shape: (5, 5, 1, 4)\n",
            "kernel shape in output: (5, 5, 4, 1)\n",
            "channel axis\n",
            "kernel reshaped : (5, 5, 4, 1)\n",
            "{'input_shape': (32, 32, 3), 'name': 'gausslayer2'}\n",
            "kernel shape: (5, 5, 1, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0618 08:02:14.816340 139788871563136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0618 08:02:14.863960 139788871563136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0618 08:02:14.865415 139788871563136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "kernel shape in output: (5, 5, 4, 1)\n",
            "channel axis\n",
            "kernel reshaped : (5, 5, 4, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0618 08:02:15.485210 139788871563136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0618 08:02:15.681276 139788871563136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0618 08:02:15.692674 139788871563136 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ChannelSeparator0 (Lambda)      (None, 32, 32, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "ChannelSeparator1 (Lambda)      (None, 32, 32, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "ChannelSeparator2 (Lambda)      (None, 32, 32, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gausslayer0 (GaussScaler)       (None, 32, 32, 4)    4           ChannelSeparator0[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gausslayer1 (GaussScaler)       (None, 32, 32, 4)    4           ChannelSeparator1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gausslayer2 (GaussScaler)       (None, 32, 32, 4)    4           ChannelSeparator2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "merge (Concatenate)             (None, 32, 32, 12)   0           gausslayer0[0][0]                \n",
            "                                                                 gausslayer1[0][0]                \n",
            "                                                                 gausslayer2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 30, 30, 32)   3488        merge[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 28, 28, 32)   9248        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 28, 28, 32)   128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 28, 28, 64)   18496       batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 28, 28, 64)   256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 14, 14, 64)   0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 14, 14, 96)   55392       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 14, 14, 96)   384         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 96)     0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 7, 7, 96)     0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 4704)         0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          2408960     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 512)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 512)          0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           5130        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 10)           0           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 2,501,494\n",
            "Trainable params: 2,501,110\n",
            "Non-trainable params: 384\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nZVKELWLgyT",
        "colab_type": "code",
        "outputId": "c37e8ff8-08e5-4834-d04c-b4e81eaf0ff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "plt = True and nGauss>0\n",
        "if plt:\n",
        "    print(\"Plotting kernels before...\")\n",
        "    import matplotlib.pyplot as plt\n",
        "    gauss_layer = model.get_layer('gausslayer0')\n",
        "    ws = gauss_layer.get_weights()\n",
        "    print(\"Sigmas before\",ws[0])\n",
        "    u_func = K.function(inputs=[model.input], outputs=[gauss_layer.U()])\n",
        "    output_func = K.function(inputs=[model.input], outputs=[gauss_layer.output])\n",
        "\n",
        "    U_val=u_func([np.expand_dims(x_test[0], axis=0)])\n",
        "    \n",
        "    print(\"U shape\", U_val[0].shape)\n",
        "    print(\"U max:\", np.max(U_val[0][:,:,:,:]))\n",
        "    num_filt=min(U_val[0].shape[2],12)\n",
        "    fig=plt.figure(figsize=(10,5))\n",
        "    for i in range(num_filt):\n",
        "        ax1=plt.subplot(1, num_filt, i+1)\n",
        "        im = ax1.imshow(np.squeeze(U_val[0][:,:,i,0]))\n",
        "    fig.colorbar(im, ax=ax1)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Plotting kernels before...\n",
            "Sigmas before [0.05       0.06666667 0.08333334 0.1       ]\n",
            "U shape (5, 5, 4, 1)\n",
            "U max: 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAEnCAYAAAB8EZ0vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x360 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yoSOWkmqSUf",
        "colab_type": "code",
        "outputId": "fed196ac-c822-4ad9-d7dc-03338ea6c495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1585
        }
      },
      "source": [
        "\n",
        "from lr_multiplier import LearningRateMultiplier\n",
        "\n",
        "multipliers = {'gausslayer': 1.0} # no batch normalization is 0.1, batch norm requires larger learning rate???\n",
        "opt = LearningRateMultiplier(SGD, lr_multipliers=multipliers, \n",
        "                             lr=0.01, momentum=0.9,decay=0.000005000)\n",
        "# Higher decays hurt the process\n",
        "print(opt)\n",
        "#opt = SGD(lr=0.01,momentum=0.5)\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "steps_per_epoch = 60000/batch_size\n",
        "\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        steps_per_epoch=steps_per_epoch,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0618 08:02:17.011099 139788871563136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<lr_multiplier.LearningRateMultiplier object at 0x7f22d885dac8>\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ChannelSeparator0 (Lambda)      (None, 32, 32, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "ChannelSeparator1 (Lambda)      (None, 32, 32, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "ChannelSeparator2 (Lambda)      (None, 32, 32, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gausslayer0 (GaussScaler)       (None, 32, 32, 4)    4           ChannelSeparator0[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gausslayer1 (GaussScaler)       (None, 32, 32, 4)    4           ChannelSeparator1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gausslayer2 (GaussScaler)       (None, 32, 32, 4)    4           ChannelSeparator2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "merge (Concatenate)             (None, 32, 32, 12)   0           gausslayer0[0][0]                \n",
            "                                                                 gausslayer1[0][0]                \n",
            "                                                                 gausslayer2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 30, 30, 32)   3488        merge[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 28, 28, 32)   9248        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 28, 28, 32)   128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 28, 28, 64)   18496       batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 28, 28, 64)   256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 14, 14, 64)   0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 14, 14, 96)   55392       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 14, 14, 96)   384         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 96)     0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 7, 7, 96)     0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 4704)         0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          2408960     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 512)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 512)          0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           5130        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 10)           0           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 2,501,494\n",
            "Trainable params: 2,501,110\n",
            "Non-trainable params: 384\n",
            "__________________________________________________________________________________________________\n",
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0618 08:02:17.616471 139788871563136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "469/468 [==============================] - 53s 112ms/step - loss: 1.8124 - acc: 0.3548 - val_loss: 1.7315 - val_acc: 0.4131\n",
            "Epoch 2/100\n",
            " 68/468 [===>..........................] - ETA: 36s - loss: 1.5729 - acc: 0.4323"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3762b6146be9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                         workers=4)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wDoXk8trXkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyxCWeylLhff",
        "colab_type": "text"
      },
      "source": [
        "PLOT THE FILTERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztpCKIbUS1JR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF4aI5BOLsqI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "32d4b995-942d-4c75-e13b-c5515731dbd5"
      },
      "source": [
        "if plt:\n",
        "    print(\"Plotting kernels after ...\")\n",
        "    \n",
        "    print(\"U max:\", np.max(U_val[0][:,:,:,:]))\n",
        "    import matplotlib.pyplot as plt\n",
        "    ws = gauss_layer.get_weights()\n",
        "    print(\"Sigmas after\",ws[0])\n",
        "    U_val=u_func([np.expand_dims(x_test[2], axis=0)])\n",
        "    \n",
        "    print(\"U shape\", U_val[0].shape)\n",
        "    num_filt=min(U_val[0].shape[2],12)\n",
        "    fig=plt.figure(figsize=(16,5))\n",
        "    for i in range(num_filt):\n",
        "        ax=plt.subplot(1, num_filt, i+1)\n",
        "        im = ax.imshow(np.squeeze(U_val[0][:,:,i,0]))\n",
        "    #fig.colorbar(im, ax=ax1)\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "    print(\"outputs  ...\")\n",
        "    \n",
        "    n=5\n",
        "    \n",
        "    out_val=output_func([np.expand_dims(x_test[5], axis=0)])\n",
        "    print(\"Outputs shape\", out_val[0].shape)\n",
        "    num_filt=min(out_val[0].shape[3],12)\n",
        "    fig=plt.figure(figsize=(16,10))\n",
        "    ax=plt.subplot(1, num_filt+1, 1)\n",
        "    im = ax.imshow(np.squeeze(x_test[5]))\n",
        "    print(\"input mean,var,max\",np.mean(x_test[5]),np.var(x_test[5]),np.max(x_test[5]))\n",
        "    for i in range(num_filt):\n",
        "        ax=plt.subplot(1, num_filt+1, i+2)\n",
        "        out_im = out_val[0][0,:,:,i]\n",
        "        im = ax.imshow(np.squeeze(out_im))\n",
        "        print(\"ouput mean,var,max\",np.mean(out_im),\n",
        "                                       np.var(out_im),\n",
        "                                       np.max(out_im))\n",
        "        #plt.colorbar(im,ax=ax)\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Plotting kernels after ...\n",
            "U max: 1.0\n",
            "Sigmas after [0.04945168 0.05052903 0.17554562 0.04526363]\n",
            "U shape (5, 5, 4, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5wAAADkCAYAAAD0KyvgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1152x360 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "outputs  ...\n",
            "Outputs shape (1, 32, 32, 4)\n",
            "input mean,var,max 0.38357207 0.031253185 0.827451\n",
            "ouput mean,var,max 0.53026396 0.027984126 0.8274598\n",
            "ouput mean,var,max 0.5302681 0.027984517 0.8274661\n",
            "ouput mean,var,max 1.2645123 0.1457591 1.9321104\n",
            "ouput mean,var,max 0.53025866 0.027983626 0.8274517\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6IAAAC8CAYAAABizBPxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztvWmQJdl5nvedzJt332rr7uptumem\nZwYDAhgAAxAgAJoCBRmmwwZlyw5CYRmyEYbCNm3S5g8iZIdFOfyDipAI2yEHJUiAB3SAhCiCMiCJ\nJglCEwJBkAAag9n36X2rvW7dumvezOMfXYPqk+83Xberq++SeJ+Iju78+mTek+e8efLkvfm9x1hr\nhRBCCCGEEEIIGRXeuCtACCGEEEIIIeTHCz6IEkIIIYQQQggZKXwQJYQQQgghhBAyUvggSgghhBBC\nCCFkpPBBlBBCCCGEEELISOGDKCGEEEIIIYSQkcIHUUIIIYQQQgghI4UPooQQQgghhBBCRspdPYga\nYz5ujHnFGPO6MeazB1UpQiYFapykHWqcpBnqm6QdapxMM8Zau78djfFF5FUR+ZiIXBGR74vIJ621\nL77VPrVizh6qFp1YdzCAcs12z9n2PHxeLuWzEPO1D41jCCXP2fja87jBQ0URlvKwnLZvlKhHpLS7\nVfbz/AzEBjHuOwjDxMGwjGf2/71DZN36a32iSmnIemQy2Hv90NVGPKRWG53uqrV2YajCt2E/Gi/P\nBHbuWN6JLXcreOyGe75WEa+p4LWR8zGm6Sa2bswzWj9grBeh3nyD15BGGLknEQ8UvWldqMlyoFwL\n/b3rYLH6KtopJWNWq5eqcSWk9KcNlD7ouedpcIhR6axeGYvGqe9b6kB9u7EU6FtExC+VbDAz68Ss\ncpv3E/2llYlxmiLi72/OJYqe1Q8d9vBqXw/RX0MeX9vXS1ze2uxJPSUlpjVHsm5qmWE/U7s+lFjy\nPLVrzwsx2Ny+xnkKx/Hb8uMyjg/ZHCrvF5HXrbXnRESMMV8RkU+IyFuK/1C1KJ/71M86sZeXl6Hc\nt555w9kuFYtQ5n1nTkCsrvSIbXUgFlr3IgnKBSijPWhtbTUhlsvlICYe9m6j7daj0etBmSiDd618\neQ5i6y1U+o2VRDt2cCCoBnmIaXeCgaD6W6Fb31wB22wwwP3iEBVbzmE9FmbxPC8tLbl16IdQRruR\n/ctnXrqohPfDHWt87lhefvX33uvEfvPVn4ZymT+oO9v9Kp5J8NNrEHtwdhVigxi12gpdXZYC1FvW\nx7650JiFWC3XhZjGlc2as91ex+tWIjxPU0Ctest4XZWuaL3t0p/Zs8jN4ys3iyBxeUcocfFQgqJc\nLhJWMdY5iudZed0dgrNbyhdUymk//Y9/ZSwap753ob5d0qBvEZFgZlaO//f/gxOLlQlb5aJb8UiZ\nCrSOK/fEunIf8/Z+YtLK2Bgbz/a0pwXlgIpWvY57rWVa2kRb0bhS/WALY4W1xBfaKBkZ5JUHFuWU\ntH39fuJHBm0ir9Q1VmbC/bLyg4JSt6Sms0380MISjk//5k//Z85TOI7flh+XcfxuXs09JiKXb9m+\nshNzMMZ8xhhz1hhzttFBkREywdyxxrc3tBGAkIllT41T32SKueMxPGq1RlY5Qg4AzlPIVHPPzYqs\ntZ+31j5urX28VlC+MiRkyrlV4+WZYNzVIeRAob5J2rlV436pNO7qEHLgcBwnk8rdPIheFZFb3489\nvhMjJC1Q4yTtUOMkzVDfJO1Q42SquZsc0e+LyBljzGm5KfpfEJG/frsdjO9LUHZfSu5fugTl3vvI\nKWd7tl6GMhXNmWgb3yW3BXz/u15yX6qOI8wjjRRjokIOm8soSQiDLr6CXA0S30Apx2/18IVw38fX\nhEwX34XPJr5S6CqZydrLGOr3YoopUJD4zmJ7owFl4gjbolbBBPhiDnNhjcV9S3n3F/RMsg1FxCr7\nHSB3rHHfxFL3206s28N6D37a7cPFeWzPk5WNoSrpKeYXJ0s33M9Tkmw6EdZrvoh608wCOgPc92jd\nTQq6hlWVThPzg72MkrSj5EPFOTcJIdOGIuIpb//HQ76IkczxyjawDlrOUXcOkyPCsnJOSg5FmLg8\n4kDJTbmnEr8zjVPfu1DfyZ0xNG36FhEx+UiCM25fL1RQNyv3u7+cVgrYOY9UUeOlDN7nM0ojlDLu\n8XwlyStU3EbW+/iL7kDxz+hHipdF350brW7jsTpdvDZi5VjdVRRmVEjkoCoaHyg5b6rpk3ZZha6+\nkoZSInoum/aZYUW5RrPYB0HTPadgG9siyir+HAcH5ynCcfxWpm0c3/eDqLV2YIz5RRH5I7lpWPtF\na+0L+68KIZMFNU7SDjVO0gz1TdIONU6mnbv5RVSstX8gIn9wQHUhZOKgxknaocZJmqG+Sdqhxsk0\nc8/NigghhBBCCCGEkFvhgyghhBBCCCGEkJFyV6/m3ilWjAw8Nxl5ro4L0x5ZXHC2+z1MTO5vNSG2\n3cOsYD+LyfaR5ybaxn1cwDWf0zKHMRs3GiiL3GrJvj3XEKmoZARnMvi9QFZJ8A4zWI+VxLm3umiG\n5BtM3A5yGCsEmLlf8d1+qxTQ+iifxWN5RmkMxQyp11X6LrGrF2ttPVnfpUTWk63Ybb/TC7jg8185\n9JKzvRqiIdfmAI22zjXnIJb3sV36iRW6exFe6odzyorjCppZQMYoZluJxalnSmgCls3gfqUcOkpc\n1VZ8vu4eX1tUOc6g3vrKpawl6dtEE/VrUESiorLfEIvRi+Bi8SIiceL61q4X1ahjTFDfu1DfLmnQ\n95tkfPce+85ZNCGtHnKNXPLKKvLNCE1PNDOhwEPdFBOr2ec8vA4CRadlH51Q2koja7pPXms55dpr\nF/FY7RCPtdJD4xm75O7rdzVtKRpXXBWjHO6rDClYB2XWGweK7pW5l4mwbjZhYjMoKKYwRWUeNEY4\nju/CcdxlHOP4ZM3iCSGEEEIIIYSkHj6IEkIIIYQQQggZKXwQJYQQQgghhBAyUkacI2oljNz3xA8d\nPgLl8rnEAsE+5lnE7S7EtBVVCwV8b9xa913vTDIZUUQKeWUx5gHmgGQzmAeRLWB9t5vb7rEifF87\nyGJuZnNrE2IV5V1vE7l5Ic0Wto9RujtQ8l6NksOZCdwXwOtFzAsoKXm1kZLXObD4mZtbmAcwCN33\n9OvlCpTxvMn6LiUSTxqR248/Pf86lDsauItA13zMkX25szjUZx4t4iLTYWJh6OTi6CIiJ3OYE6Ll\nEs1mMUd7Rlml+Y22m9ut5WzU5zAf442teYiVatr17eorv4F5HNbg9RhnlbweJcchSuT69Ofx+F4F\nxwA7QA3aEGPBGl5/yQXYe/N4bShr0Y8N6nsX6tslDfoWETHGiu+59Xy4eAPK1ROaDi32zZU+emC0\nPLxPVjOom6LvzlOSOaMi+nVV8fH4Wt0iJRdzNbFyfT2L9Yos7rfRx/lAq4vXWpRL5IjiKYlR5kZR\nfrictMSwIFFR0VsRdS9a/pyicdNS8l4ToUFJ8fUoT1iOKMfxH8Fx3GUc4/iE3QIIIYQQQgghhKQd\nPogSQgghhBBCCBkpfBAlhBBCCCGEEDJS+CBKCCGEEEIIIWSkjNSsSKwVsUnzGkwU3mg03RJZTOzt\nK/nmBcUkqFxUksvFTfb1IzQJsorJTrmE5ZRcYhmEmMCcLbhN3W0rWfrQNiKHariAcBBiQvd9x9yE\n8dXeCpTph0qjaTn0illRc9M1E4pzWIdcFc2E/Ax+16H5C+WyKMVkNZRDiT+lX6X8xfYDzraWVK8t\nfL5YRFOnBwvLEEsaUeQNaitUVvZ+pHAdYp5BPWwrC7UnzQKWeqgHjY8soEnCU8EJiP3wjGuIUbqO\n13amN9wC6RrZTbecSTpfiEiYV4wBMkrivrLweZRX6pYIqQurZ4ZbiHqSoL53ob53mQZ9GxHxh1j8\nfSl0V5L3FLNEjXqA18LhAHVf8V3DlLxBA5LAYH8lTZREdGOidoymRklixZhIu16O5LD+2r4/OObO\noboNNJ3xFf+XSDMmUmJJvcG2iGpMpGlcq7/NKkZKyTK+UqaA19o0wHF8F47juxz0OD6l03hCCCGE\nEEIIIdMKH0QJIYQQQgghhIwUPogSQgghhBBCCBkpd5Ujaoy5ICJNufma/MBa+/hBVIqQSYEaJ2mH\nGidphxonaYb6JtPMQZgV/SVr7eowBY3nSbbgJqv3+pgsu7TkmhUdPTwLZXKKMVEUKWY8Sv5sxk8k\n+2qOQx6aKInF45sITXs0B6Ns1q1vp4NmRVtdTASfOYTnPqdk6duqazwwMFhmdQUTyE/MzWFdA5TF\n2sqmsx0oxx8M0EwhVn50t4rDUCGH/ZnPuu0Yx9iZ2YzSTwfP0BrPSCyzfiIZPq5Bub9YOuVsf3Tx\nVSgzn9uGWCca7nwrnuv4oCXyD4svw5lwJI0MrnbqUOa1rQWIvffoBYh9cFbR0sOubp4Z3AdlCtdR\nu90H8BrN5BRThCV3bIpzynmHqN1YSfgXxegiLuH4EReTAeVYOWVcO3iG0jj1vQv1nSg32foWGXYc\nNyIZ363TxgANWa713P4/ntuAMkUP7/NaLGlMJIIazyv7aQRgn6Pfh7OK0VFk3XINL9mBItsRmhwt\nZjch9p7aZYh1H3Sv7xf8o1DGa+AYEJdRzyZQzFfaQ0xpFT3HiuGLNne0WeUzhxiy4mAkZkWcpwwB\nx/FbmJBxnK/mEkIIIYQQQggZKXf7IGpF5I+NMT8wxnxGK2CM+Ywx5qwx5myjpfhyEzLZ3JHGmxv4\nDRkhE85tNU59kxQwtMYHDXwziZAJh/MUMrXc7au5H7bWXjXGHBKRbxhjXrbWfuvWAtbaz4vI50VE\nzhxfmKwFwwjZmzvS+KmfqFDjZNq4rcapb5IChtZ46aFFapxMG5ynkKnlrn4RtdZe3fl7WUT+hYi8\n/yAqRcikQI2TtEONk7RDjZM0Q32TaWbfv4gaY0oi4llrmzv//isi8r/ebh/Pz0ip5prjXD9/Ecr1\nY/f5OJ/HhPkoxMR9W8JyWlLtILFvoagY73gYyxpMCo63MVE7m1XqkXGT1RXfI+m30Uyo0ccE5pzB\nbpvNu2323vvmocxGBQ2BbIhfjNkMxtpZt8L9UDkBxaSp1WpBzPMxcb9QxDZLlvMzuF/SeOog2Y/G\nc14oZ3I3nNi/XnkHlGv33WT+xWwDynQt9nPoD3fJNmO3r08E61BmKy5A7FAGNdiN0XhgQSmXJBbs\nm78IT0PsmdYJrEe2CbHHZ9yx4tRPrkGZFzYXsR5KQn4U43dwF7fda970FKMtiIj4TdSlVb7i00wA\nxEsc0cdP8BRTjoPiTjVOfe9CfSfqMYH6FtnfOJ7kcncGYs3Q1eB9eeyvmj/ca76BYhzkJ+YbeYOv\nU/pKj2nlPG3uonRi0bjzja7ixHOhi3OLtmJgVMvguX9k7nVne7GA19mlbWzrVojzsd5AMVU0ZWdb\nNS/q43mbgWZYiSGrGcMk50uK4U58ELagbwHnKTv14Dj+I6ZtHL+by+OwiPyLHcfZjIj8trX2D+/i\neIRMGtQ4STvUOEk71DhJM9Q3mWr2/SBqrT0nIu86wLoQMlFQ4yTtUOMk7VDjJM1Q32Ta4fIthBBC\nCCGEEEJGCh9ECSGEEEIIIYSMlHuYQo1Ya6WXMLm5eOkSlLvvvlPOdq+D6496MSbGeopZjrVYrlB0\nk58zOSWJt4/JuDnl+MbHJPpQSX4eDNzzLmUxub8Xo2FPbJS6+bhvkPhOwR8MoIyvmDKdv3oDYtky\nJoebRB54t9vB4yvJ4s02Ghbkclj/rBKLrdsHQYDHj6J7a3Rxp4TWlxuDmhN7+txJKPfY/a7uVwdl\nKKMZWOQ8NKKIFL0lk/4rPvZXpHwPdcRHMwIvg228HmF9txLGAw/mlqDMcrkCsYFFjUdKFn3S/KLo\noWFZcRZjXz+PJgzFHJZLmkz4baxDrBh5ZTex3KCgGFbkFUOMpJmakvBvB5PzfSH1vQv1ndg3BfoW\nEYljI1ttt6+vFupQrp51Naf1qabBvMG+CQzer5PGQSVlP82EqKKZGikGOl1Fl31xY3M+mjFuZEoQ\na8c4t/CVe3PSvOm9lQtQ5nAODWaebxyF2HpXMThMXMtxqMzZlJinmBXFgWbkqJkaJc2KsMikwXF8\nF47jiX3HMI5P1h2AEEIIIYQQQkjq4YMoIYQQQgghhJCRwgdRQgghhBBCCCEjZaQ5ov1+KJcuX3di\nRw7hwq7JN7Fb25hnWA6U96JjzLMIfCVfM1HOV5rBFzxWr4n1CJRc1TiLx2v3E/kkfXyHvq/kVPSV\nujVDzJmt5d38ySK+zi6VAuZ+zs7j4tGluRrE2p67KO96exPKREpean0Wj6/liFqL76pnPH/PMpPG\neliS377+ASd2+vgKlMv7bludb89BmQeKqxDrKXm4NSWvIrkIdNHrQZmSErsRYd/XPdR9X8mXuNh3\nFzrXFjnfDFGDm33M9XljCxdNf7jm5nKcUhaQf3vxKsRenMMx5mQJF87+o+23Odt2Bdvaj3A86c0p\nY0B+yNzlZF7LhEuc+t6F+h6CKdO3iEgcedLZdvvWm8eKB56bG9ezeK/WFqn3kzmFIuIrDRMmZkJa\njl1wFw3aVPI6k3mDmxFqt6tco+sh5o0u9aoQS+Z/nsyhxrXYVikPsXKA1/fatlvfboT7GUXjcVbJ\nlcspGlf6bpicUCVFd6xwHN+F4/gQ3ONxnL+IEkIIIYQQQggZKXwQJYQQQgghhBAyUvggSgghhBBC\nCCFkpPBBlBBCCCGEEELISBmpWZEYI9a4ibW+hwY32w13sdpDNUx6z2oLC/toAKQtttvcdhdpHigm\nOOUAk5yLVUzIDwe4bzPC5OFe1n3mj2NcqLZQnYVY1Mf22VrF5Oew4RoYHa7igrxaAnMQYDJ/kMek\n7HzVrUfnygaUKWTwvIMcGiKIp5gFxNiOxnfbLOxhm/m+4so0ZuKEe0HS1EJE5Mq2u0D6Bw+dhzKz\nmdZQnzebwUXHX2gfc7a3lX5+OH8NYvdnMDm+EWMy/3c6ZyC2HLqaG8TYN4t5XKy8q1wvlzdxAflW\n6GqpcBivd83soJpFk4SZAI0NSgV3324LF8MelIY0tdDQiiUvhVD5bjCD+hkn1PdNqO9kQSU2hfqW\nWMR23KlRZ4B9GCbmCDmD9+phzVcCZd8wYX7UUnRayeA9MW+wI9YVY6IL4QLEroWuLmOL/VXx0Sxx\nM8Q5w1IX5yCN0L1OfaWuM8q4UPaxzXoZnL6ahN68njJPVIxW4tyQ7iuxdrzEvopB1STCcfwmHMeT\nBZXYPR7H+YsoIYQQQgghhJCRwgdRQgghhBBCCCEjhQ+ihBBCCCGEEEJGyp4PosaYLxpjlo0xz98S\nmzXGfMMY89rO3zP3tpqE3DuocZJ2qHGSdqhxkmaob5JWhjErekJE/qGI/NYtsc+KyDettb9ujPns\nzvav7nWgwSCS1bVNJ7Z8BZOf3/XoQ852PosJzIM+JvYWc5hMLBGaANRriSR6g0nOWSWZuGfxWA0l\nsXdN0NTIL7qfWSjhdwCzRw5DLGiiMVG7j2YBzVU3eTvoYuJwx2LS9MBDCWxu4fE3tt32WGlggvrx\nOhoibLexXBRjowUB7msS+dbZAPvXS7oT7I8n5IA03g0DeXXJNYEIr6EefvJ9rzjbi9lNKNOMUPf3\n55b3qoKIiLy/fG7PMgt+E2JLESa+P9U5BbHvbWAsn3H1dURJ+P9Q+VWI1fwTELvRQoOy5YZbt6eD\n41DmehH32w7x+n5mE/fdWHOPP38NE/63HoCQBA00O1A80iRWhqdBUr5ZvDaMP6TJwO15Qg5A49T3\nLtS3y5j1LXJAGjehkcJV9754vjoH5Rbuc81XAsV4sWvxvjZn0LSl7qEpSRJfc9lR0IyJLg/QCDFp\nTCQi0hi4pkN5D+cMhwLUfZhDjVzrKBpvu/MgL3mTF5H5LM4ZOopRzJWWYhSz4ta/uKkYI+LlIuLh\nfMz2sW5WmTGDehWNH5B/0RPCeYqIcBy/lTSM43v+Imqt/ZaIJC2qPiEiX9r595dE5Of3XQNCxgw1\nTtIONU7SDjVO0gz1TdLKfnNED1trr+/8+4aI4E95OxhjPmOMOWuMOdvq4q+MhEwo+9J4tDWclTkh\nE8BQGqe+yRRz5xpX3uIhZELhPIVMPXdtVmSttaKuzPSj//+8tfZxa+3jpbz2TgQhk82daNxX1pol\nZNK5ncapb5IGhtZ4kRon0wfnKWRa2e+D6JIxZlFEZOfv4V4IJ2R6oMZJ2qHGSdqhxkmaob7J1DOM\nWZHG10XkUyLy6zt/f22Ynba2tuUb/+ZPndjRWfxmplZxE9pXl/Haam9jAvPJE4cgVi1iIrVNfGcU\nx9gM61v4mQMliTczfxRiJ44+BrF2w30t+dobaNI0aKExQEX5djZXKkBsq+meZ1yoQJmuxe8dohA/\nc325AbHnX3Pr24XsZZEwxi/jjKdk6SsGQ4MYs6YHA9f8wVcy/g/IrEhjXxrPbHgy+1W3z7ZOY7v/\nROWas/2dDcwu1xLh/6Pj+Hr7Y/lLEIvEbZeuRfF+u/UwxDTjgYqP5lW/cOR7EDvXc6+/P77xNijT\nGuBbEW8rXYdYPY9mZEubrqYHip6XO6j7MMYk/csraC5Y/75bt6CNyfdeT7mG8sOZiBj0MhETuv1k\nfdSzje7ZKlt3rHHqexfq22UC9S2yH413rMw/557MtRrqJne/W6anuHxsKH14MkADworXh1icuN+1\nFI2/1sc5T2hRD5rp0JncEsTOiXu81zt4/IsdNG7StNpSzFdafddIac3H+c0gxmM1+jjnOb+E9Shc\ndtsov4ba7dcVDSoSjDOaVrGczeytcc0U5oDgPGUHjuO7TNs4PszyLb8jIn8uIg8bY64YYz4tN0X/\nMWPMayLyl3e2CZlKqHGSdqhxknaocZJmqG+SVvb8RdRa+8m3+K+fPeC6EDIWqHGSdqhxknaocZJm\nqG+SVu7pOzGEEEIIIYQQQkgSPogSQgghhBBCCBkp+zUr2hed/kCev7TqxI6dPAnlZmpuIq8fY+Jz\n6YHTEKtWyxBrbm1ArJdYzzSKMdl3tYuJw4U8Hr9ePwKxchmTt9trF5ztjJJY/cOnnobY2toKxE4d\nwyT9XiJROONj11ZLSvusYftsdDCpORbXLCC2aH5wo4lrU9XzWI+C9vWHVaQYuAWjCPtJq8c48Ztd\nqX/zNSfW+K8w2f6nSm6Zoo8aP3PkBsTelV2F2PN91MPywL2G2jEm3397HY0Hjha2IPb4zDmIPRJg\nPZImAPkM9s03v/cTEPuzpXdBrPcwmgDEHVcjSwEm/B+rodHWjQaWG6yi2YEXubo3EV4H5csY684r\n5ltDuuODL0CkmAAoY9G4oL53ob73Ztr0LSLi92IpnXfNEP3H61CuFrh9eDqH9+pjGby/nsigBvuK\nocm6dfvwQrgAZc73MDafQSPHdwSXIVYyqN+1gTtH2B5kocwzS8cgtt1UzJwKeHzPc/WV8dHFx1NW\nIFlu4twlXsNrPpu4PLLbioEiTiNERNE4+iNJlFOOlzButIpBo+IVNVY4ju/CcXxv7vU4zl9ECSGE\nEEIIIYSMFD6IEkIIIYQQQggZKXwQJYQQQgghhBAyUvggSgghhBBCCCFkpIzUrCiTycjheTfpP5cv\nQrmlVTeRN8C8WCnXaxDr9THp2PqY/BwU3AT8jeYyHksxzzkyfxRi2QxmtDeuXoJYf/26s10vYGLv\nIw9iUvYzyjnNLR6HmLVucnKvj0nlQRnburOCydxbHdy3P0geH9KXRTz8XqM4wHK5jJLM7wUQ64Xu\nvuEAXQb8zGQZXdhcVgZn3P6JMN9c/nXDTXyvZTDpXUu0X4rQPCJSjBbqftvZ/l4TtdXoo3Y/vvAC\nxBZ8NL/4QQ8NKzYGrr7eUb8GZbLvRHOKl76LxmOLC5jMH1n3PFs9bItSgNrttrFcdgO1mvQPC9qq\nqwUQllGDWp9bRap+x62HxeqLzaDxwLigvnehvl3SoG8REZvxJJxNmPMpM6VLrRln+7ES3vc1Y6Ki\nMp/pWgyGiTnI+gANe0Kl0Y8EqK26hw2/FuP1kTze6eIalNmawf3OySzE5kptiBUSxjAZTzMgxLbo\n9nB+kGkpGu+5WvJC1JYyFEnYUzpF0bhmdOQl9jUDrFcGvSnHCsfxXTiOu4xjHOcvooQQQgghhBBC\nRgofRAkhhBBCCCGEjBQ+iBJCCCGEEEIIGSkjzRGtFHLykXe4i+ZWipi3+IOnX3G2H33oJJQ53Mf3\nosMQ3+vudvoQyxXcd87zZVxI9kilCrHZ2XnlMzGHc+sa5opELfdd8trcISgzf/gExo4ehlilhu/M\nb225uSjZLL5vvraEC24bH7+LCHK4ryQWaS4q+aaewfbPBHj8chlfTO90cd9+7PZxpOSbBnay8ov6\ndU8ufMJtm7CO9f69777P2f7gO1+DMs0K5sVsKnk9V0PMzzmS2XS3c5jLcOQQxj5SeB1iDWWR6Rc6\nmKfcSeSFvLOMi6j/TPUliD3z8fMQ+4kC7vtsxx0HtIXbv9PAHBMlNUViReJJelVMltDyJ7Rj9atK\nblIbK5JcHzy5OLqIiNL8Y4P63oX6dkmDvkVEBnkja29z71FRSckZWzribJ8uYT7le/I4F1CWh5dN\npRG61r0+an4LyhwNNiD2aHYJYkWD/bWmpJYlc/a047+7eBFil+fn8DOVvNRkDmryHEVEXmotQuxi\ndgZiXUX3NjHdsD4Wsp6iQUXjg5Iyt1BCXmIKaLpKXl+H8xSO47twHHfhL6KEEEIIIYQQQkYKH0QJ\nIYQQQgghhIwUPogSQgghhBBCCBkpez6IGmO+aIxZNsY8f0vs14wxV40xT+/8+bl7W01C7h3UOEk7\n1DhJM9Q3STvUOEkrw5gVPSEi/1BEfisR/5y19u/fyYdlM76cnnVNgK4v42K4nb5rDBALZtl6Hmbj\nZgPMlm0LLsC7tu4m4Jdn61CmVC5BLMiiyU4ug3WbOYkJ0mtLbn2DIh4/U8BzypSURawHaMBUq7jl\nPA+/Y2jlsa6Lx3DB30YHDZjyxcQC331MbO93cdXmQr0GsWPaZ27h4teXri1DLInRMrzvnCfkgDRu\n8pHkH3ET8AeX0PgquRj3IOmQul7aAAAgAElEQVSyICI5xfxpzsN2ekOpx582XVOwMwU0sHgoewNi\ndWWB8SPJTHURed/8c/iZXXc4qXt47VWSzg4iUimjbjYjNMN6d/GCs503eKw3cmgC9rbjeJ4vrqMB\nWlhyrz9t8fJMF4MDrKpkT6NBQWcdDRzKr6PRAxxfMdfYB0/IAWic+r71WNT3raRB3yI3TT3ax1wT\nD1tErfba7rmt9JV7taL7yOD5bsbYyElzlzl/G8o8qmj8dAbnKYHBucWCj/q64rvmK9ovFXmlux4O\n8F7dtji9HMasKFba7FwVjSLfyOO4Y5PzHsXM0CixQRFParCA7SMhlsvdcM8hg0OY+Dhl2w9PCOcp\nIsJx/FbSMI7v+YuotfZbIrK+708gZMKhxknaocZJmqG+SdqhxklauZsc0V80xjy787oAemvvYIz5\njDHmrDHmbKt3MF8LETIi7ljjkfLLLiETzJ4ap77JFHPnY3gLl0khZILhPIVMNft9EP1NEXlARB4T\nkesi8g/eqqC19vPW2settY+XtPUpCZlM9qVxv6q8/0DIZDKUxqlvMqXsbwwvYdoMIRMK5ylk6tnX\ng6i1dslaG1lrYxH5JyLy/oOtFiHjhRonaYcaJ2mG+iZphxonaWAYsyLAGLNorb2+s/lXReT525V/\nE19EysZNFF+sYIL/0pabdNxuY5Jwt4uJyVGkJOiGmEi9vtFw61XFOswVMZbPYxJvM2F8JCKS9dE0\nyffcffsdNPvJ1TGp2SoGQLaP5aJEAn4QYHLxoZlZiMUxfhfRbKEpQrvrJnQvrW1CmUKAycrF0iLE\n8nk0U6jW0Yzgyqr7Gcl+ExGZr9ybX9n3q/HAj+RwJdF+mG8u21dcY4AbLTQKuBZVINaKUVvbEbbn\n0xuuYVZRcUv4meJrEFvMoO5f6uNrPDM+6qboudfkmmLAcdjHPtTMKWLlO7J25J6776PpxMdrz0Ks\nF+Mw9/rmKYhlm+7xqhfw2gsrigFHGes6U8DxafH+LYjdOJ/opyU8p/aRAzFzAfajcep7F+rbJQ36\nFhGxvkhYd+cSlTl8XTcM954+NWPNOAjnKZru3+gmDE3wUFJRTFtCi3OeRox9PePhfKaWMBxpxNhf\nXQxJqOi5q5oVubG+RROlso911ci0UDf5Tbc98hs4z+rV8DPjLJ5UqY4mNorPkQxW3bEtUOqV6Sg7\nHgCcp+zCcXyXaRvH9xxJjTG/IyI/IyLzxpgrIvJ3RORnjDGPiYgVkQsi8rf2XQNCxgw1TtIONU7S\nDPVN0g41TtLKng+i1tpPKuEv3IO6EDIWqHGSdqhxkmaob5J2qHGSVu7GNZcQQgghhBBCCLlj+CBK\nCCGEEEIIIWSk7MusaL8YEQkSye8zBUxqzhfqzvZstQ5lrMXE2CCLx6rV0bTn4o3rznZDWTfs4Som\nZb/47HMQW72+DLG3n3kEYl7gHm97YxXKLL/6AsRMBs+pXMT2aCXOIYrQsKDZw8Tk165h/c9fvASx\nG+tuAnNHMYHyiljXOEYzBVHy9nNK31Xn5pzty8vYZtnWZK2H5RkrpYybcH//DK5BvZp3++Kds9eg\nTNLYQUSk7uP5vqdwAWL/vP9uZ/u5xlEo88A8mlX86tJjEDu7hi4Gf+f+r0Msn7gkX+wehzJ/2Hgn\nxDyDgngofwNiSfOOdoxGVee20fTquRex/kdews+snnfb1m8oZhU+GjMYxWRAo5bF412qJ8bD1xTD\ntTyaa4wL6nsX6tslDfoWERHPii26JjenZtCUsDdw22UxjyYfgUGznECwDbIG76erPdeQZaAYC74/\nfx5iz/Rx7rI2QHOXDynXVTdhHvSD7gkosx7hsULFdCivnPtS6NbtahfnMq9uLkDs+qsYm30DQlK8\n4Ro5Bk00vxkUcVxQfGikkEVTyFwGz+l6wb1mNK+lbFOZB40RjuO7cBx3Gcc4zl9ECSGEEEIIIYSM\nFD6IEkIIIYQQQggZKXwQJYQQQgghhBAyUvggSgghhBBCCCFkpIzUrMgzRorZvBOLFOeajUbT2Tbe\nHJTJVTAhvx/hc/Wgi0ZE3Z6bhH759StQ5h2PYjL09kYDYvNVTAqenZ+F2JVzl53tp555FsrUDs9A\nbG15DWKHFzChe3XbTWC+tIL7NdqYRX/tKpoVddpoapRPJvh7mJhcK2GfmAGaMFRrJYiJYnQ0M+8a\nFPSjl6FMo49mBOMk60VyvLjpxDoRGmad23A14hlM/j7io/nFWlyEWDPGZP5mx73ObpzHa+jqKTQU\nON/Cco/PoXnVh3JY3y83F53t//2HH4UyczPbEFtZRt2cOIrGCVeXXWOL7Gt43nncTe47h6YTQRM1\nPihhPyXpLChl0DdNTtWUiigM5t26ZTp4sMKa8gFjgvrehfrem2nTt4iIGCuZnHvfKmeU9kyYB+U9\n7AfNsMdXTE80rrZrzvYPt49BmWO5TYgVPaxrRXHQiZSOfaF/xNl+cvNtuJ9iFLkd4v27PUCTlgur\n7rgwuIxzgfwyzuMWrmGbFdaxbZOnFBVxihsW8PhxgMevF9C0pRJgO14tu2OKN8DPzDZQG+OE4/gu\nHMf35l6P4/xFlBBCCCGEEELISOGDKCGEEEIIIYSQkcIHUUIIIYQQQgghI2WkOaLGGMl47rNvo43v\n4a9vuO8tz3dx8de+9sJzEXMsk58nIlKbcd97/5f/6ltQ5sypRyD2wKkHIRa18P34xia+d72xvuJs\n18u4kPNP/9THIHb59Vch9vLLGLu25tbj9WVcgLsvmNc5UPICjsxg3Qpl913+6w08x2KQh1ig5AD7\nyrq39aOY99pI5FpEyprQjS7qZ5zcXCjafa//la1DUK657C4KvryAucZanoVGxcM2OF538z/av4W5\nOP/No/8JxP7r409CrBVj/s/TfczP+V7zAWd7YbYJZf7onf8PxP7vBuYh/dNXPgSxzAVXX/PPYf6x\n30WR+H2MbZ1GrfbL7phSO49jR7+CsSiLGs/7mO/xWAVz0c8fdnNdTFSDMsXlycmDpr53ob5d0qBv\nERFjRDzfbdN+jDetdujmQG4PUEcti3mSeYv96gn2YbPvHq/1HHpP/NP+T0Hs37//BYi9vXgVYi/3\nFyD2bPskxJL85ZkXIbY0wH792pV3QWxwyb1O66/gPC6/obRPiBrsl7FPbM2NBW1s10EBPzPOYrmZ\nHOYmPlhagdjLs4fdY/k41vntydI4x/FdOI67jGMc5y+ihBBCCCGEEEJGCh9ECSGEEEIIIYSMFD6I\nEkIIIYQQQggZKXs+iBpjThhjnjTGvGiMecEY80s78VljzDeMMa/t/I0JmoRMAdQ4STvUOEkz1DdJ\nO9Q4SSvDmBUNRORXrLVPGWMqIvIDY8w3RORvisg3rbW/boz5rIh8VkR+da+DGd999i0WMNH55IkT\nznY+g0nIgz4m2XpZTAqOI0xW9jzXoOfKNUxA/0df+grE/oN/99+B2Hwdk7cLy7gYbuNqYuHpJtZ/\n68J1iB2r4sK9KyX8zJfPX3O2zTYm2s8eOgwxKWFyeEFZbztILMLt9zExebuBi2tHC7iYbzbA/iwX\nsNziMTd5fvYQjq8rN5axsnfOgWnciBU/YTyxWGxgQTdfXg7lMGFeWwA6UBZID62ygLbvXgvei2tQ\npvtrixD77/6Lvw6xo4exX+cLLYhd3Nz7/vdMH8/pP6uiuca35s9A7KXQTZC3ytdorSPD+a8NSmhY\nESVkaTNYJtdAQwFvgBWpB2jM8HD+GsQ+tHjO2f7O4fdBmcoVxaXrzjkQjVPft4f6dpk2fYuIGGMl\nk3H1dSiP93QvcU8sKMYfbcVAJSs4T1mPyhDb2HbnRjMv4o05eh3nAl997/sh9ofH8PqrFboQ6yUM\nAsu5HpRpVlHjCxk8frJ9RET8jqu5TFuZbCihKIcaDIuo3+RQYWLczyo+l1pQM3J5qHADYvfPH3O2\nL9WreHj/QF4+5DxlB47jtxw/BeP4nleHtfa6tfapnX83ReQlETkmIp8QkS/tFPuSiPz8vmtByBih\nxknaocZJmqG+SdqhxklauaOvaYwxp0Tk3SLyXRE5bK198ye8GyKi/NwmYoz5jDHmrDHm7FYXv10j\nZJK4W423N6hxMtncqcapbzJN3O0YPtjCt4kImSQ4TyFpYugHUWNMWUS+KiK/bK11Fq201lpRX6gQ\nsdZ+3lr7uLX28WoeX1MhZFI4CI0XZ6hxMrnsR+PUN5kWDmIMz1SHWxeRkHHAeQpJG0M9iBpjArkp\n/C9ba39/J7xkjFnc+f9FETmQZD1CxgE1TtIONU7SDPVN0g41TtLInhmzxhgjIl8QkZestb9xy399\nXUQ+JSK/vvP31/Y6lud5kk+Y0hglv7Wz4XzJI+0GGgWEHXy1IBJMtm6sYHL5pUtXnO2Mh8/jq+t4\nrN/9+h9DrFZDs4DDM7MQW/BdgyRvE4/fbuErQdUFTHxfaWHCeJxzu7JnFeOEDTRlsr4PsYKSuL84\n4yZgzyvnbRPnKCISDtCYodnEBOmFHpofFfPuOc3MYltsXF+C2J1ykBoPTCSLWbdvAw/bYKntnsuV\ndh3KrJXQwEIzv3h2+zjEnjvnGig8ksWk/dxFNAZ46P/Ez+weQsOsyyfx7Z/OUVc31sMvZv/L1t+E\n2Hwdr++l69gehcRYkWnj4JFtoEmC4pkhYQV13zjl6m37KJbRvmv28FKTc9vzEItqOM6cyq862988\nhNdecfnujS4OSuPU9y7Ut0sa9H3zWFZygdvOC1m85/Yitz07Ed7/bgxqEFsWvHeebZ6GWGfdnSvN\ndrFzytfwvplvYD26daxHYw412K+7n7E6g9f2P259GGKBrxgwXcHjV9fd/s9t4X7BNmrcGtSN30P9\nduturK+ZveQx5oXYtskxTESkX8cp87Gia5LzWh2PFReGM6e5HZyn7MJxfJc0jOPDXB0fEpG/ISLP\nGWOe3on9bbkp+t81xnxaRC6KyH+671oQMl6ocZJ2qHGSZqhvknaocZJK9nwQtdZ+W0Q0w2sRkZ89\n2OoQMnqocZJ2qHGSZqhvknaocZJWDmRxI0IIIYQQQgghZFj4IEoIIYQQQgghZKTcfQb1nWCM+NlE\nIn0Xk3bDbtfdTcnF3V7fhFhcxWzcra0tiK2tuKZibz+1CGVqcwsQu3INjY9WN9B06GIbTYd6iYTu\nhSwmc7dzeKIvX74IsTeWViFmcnlne0tps36vCzGL+emy0kMjqDBy2/bYLBoyaaZP4QCzps+duwSx\n+UNHIWaq7jnNVApQBm0ZxosnVopesv0wsb4VZp1to2Sqv9o9ArFejJfsuSYm6QdL7vGXPpyFMj2l\nD2vnMLG+fBl1M/siXreZjttf28fwLaL+NvZY6+lDELvvOSWz3rix/AqaXnltNO8Qi22b7+HxvZ57\nzTcewLrGiuCgu0XkhZdPQOzZ2ZO4b8JVoDuvGF3k3uptrNFDfe9CfbukQd8iN9999BUDkyRx4i3J\n7Qjv6Rd7aAYSWrw5X2ihVpNsPIT7ZZUbfXYL655tou69EO/X3iBh5KJMvlo9ND7KK0Yli+fxMwsr\nrpiya6hx01E0HuOxchmsW7Domuu0FlHQUUExPupg7NwS9t2zVdS9nxjbwjrWNSyNdqq9FxzHd+E4\n7jKOcZy/iBJCCCGEEEIIGSl8ECWEEEIIIYQQMlL4IEoIIYQQQgghZKTwQZQQQgghhBBCyEgZaQa1\nFZFB5LrjNDbRdKhcdJOmgywmMDcVs6IMFhMrmFR76vgxZ/uh+7DM9WtrEMtXqxB72/xhiPlZTNq1\nAzfpuF7BYy038JxeuLIEsUub23h86+7rB5itHPjYQBkPy20N0MGotbbubG93MfP5UB6PXzyGRlCr\naxsQO//yKxA7/ej9zvax2Rko84piWDBOIjHSjN1k+OcaaMR0vOL2VyWD7flaEw2zygGWi2L8Pin7\nkGvSlXkHJsdvXMb2HJSwPVfegyZRcQavGZNIto/n8DODa6iRI3+OyfyZp16FWDKZ3ySNz0TE5PMQ\nkxx+ZnRjGWLFdVeXuY37oEzzviLEwoew/XNLOLR+9fxjEPuPTz/tbHunWnj8p/EzxwX1fUsZ6tsh\nDfoWEYmtkXbPbfu1Phq5lHy3/ws+6mEtLEGsEyn3yQzue9+pFWd7eRbrsLmCbRc0lHuicg0pnkkS\nZ10TGJtVjI/W8Fgzr+Kcofo8zqFMo+kef4BmMioRmtNYxVQxv+GOC34HjXS27sfrPSzjOXWv4bX2\nZ6XTEHt43r3WvFnsy+4sGlmNE47jt5ThOO4wjnGcv4gSQgghhBBCCBkpfBAlhBBCCCGEEDJS+CBK\nCCGEEEIIIWSkjDRHdDAYyNq6mzewoeR6Hj963Nmu1fEd8Yub+O705vXrELvv9AMQWzjlvlO9eukl\nKHP1lZfxWDUlH1RZObaYw2YNQ/ed9q3tNpSJlcVrZ2u4qHLbYr5B2Hf37fXxWDbE3NVWhOUGGeWd\n9sD9zmKphfU/XMF8GKMk7q4s3cC69bAP8kW3HQ/P4ILIDz2I/fvNN65CbFS0opz8xaab2/rGOvbh\nXzrxmrP9ntIFKPPlqx+A2PkNbIP/8NRzEPvZB19wtp9sPgplnrj4YYjJg/jufzaD+T8zJcyXaPdd\n3TQamDNg8FDSOop6rjVwoWXTdbVqWlgHifAD4tV1iGn5Rda414f/ymU8/qmHlf2wWOka5qa0LS7M\n/SeFR5ztty/iGPb8ux7ED/htDI0C6nsX6tslDfoWEYljI92Oe9/aDDH/7IGSm8NZ87G/XmqhR8Ja\nD3VzsoS+CR+Zed3Zfm32EJT5txlsu3AB8+c8T8mVMxizic5OtoOISNTE/LawhL9pRDN4nn7s5noa\nZR5k+5izZzvYtnG3i+US10dQxH4LjmD9A7TdEL+H57Qd41z0+cht71we6986ivUYJxzHd+E47jKO\ncZy/iBJCCCGEEEIIGSl8ECWEEEIIIYQQMlL4IEoIIYQQQgghZKTs+SBqjDlhjHnSGPOiMeYFY8wv\n7cR/zRhz1Rjz9M6fn7v31SXk4KHGSZqhvknaocZJ2qHGSVoZxqxoICK/Yq19yhhTEZEfGGO+sfN/\nn7PW/v1hP8yIiJd49l08hImxOc9N9m5t4cLIOYPP0A3F+GjJXIJY9oRrIFBexIV873s3JpwfmsGF\ne9evrkDsxuVViJUDN0G+VsCE+biI2cReAY2Dyh6e+1bo1ne1jcnc7b6yeHQXzYokwnMveG59A2VB\n3kEWjQ2ubzUhtrzWgFg/xnPvPv2Ks33y1Ekoc9+J4xDbBweocStZz23nDx07D+UOBW67vNFDI6yZ\nPBo5XNmsQezfLp3BfTNu/z+cx+TyEw+gdj94COv69Dq28evXlEWsK655xOwManAtQu2u+qibXg1N\nIQrrrtFF6QqaAPgb2GbDvvbhzdSdbZvHenkhJvdXLmKseglNBvwumh2std2x5+KDeD0Wz2xB7A6h\nvnegvndJkb5FDlDjGrNZ7Ouyj2Y5SQo+3ktjW4bYag9j8wkHnWM5nN88MItzjfYA+3W7j33T6mG5\nfNbtn3Ie+3l5gPfqzRCPH+XQvLC44s4b8ivYPn4D29VrYvubLtbN5N16xFU0ovEGqOfcZgwxwWIi\nFq+2lqk621EFjWgK2Dz7geP4DhzHd0nDOL7ng6i19rqIXN/5d9MY85KIHNv3JxIyYVDjJM1Q3yTt\nUOMk7VDjJK3cUY6oMeaUiLxbRL67E/pFY8yzxpgvGmPwqwFCpgxqnKQZ6pukHWqcpB1qnKSJoR9E\njTFlEfmqiPyytXZLRH5TRB4Qkcfk5rc0/+At9vuMMeasMeZss4uvYRAyKRyExrube7+uRcg4oL5J\n2jkIjUfKa6CETAocx0naGOpB1BgTyE3hf9la+/siItbaJWttZK2NReSfiMj7tX2ttZ+31j5urX28\norzLTMgkcFAaz9cxd5aQcUN9k7RzUBr3K5jbSMgkwHGcpJE9c0SNMUZEviAiL1lrf+OW+OLOO+si\nIn9VRJ4f7iPdZ1+rGO/0bCIZ3mCS7Vy9DrFiFW8gV1aXIfbn33ENjN77gcehzMDHC/UHz78IsbLB\nJhz4eE4zh9yk6WIGy/gNPE+bbAsR8ZSE+aRZUa2CSfqx0tbtNiZSt1v4jXCp5Lat7/tQJuzjsXot\nTIY+PI99d+wIGkYdPuqaSr344gtQZnH27t9COXiNu4QxttVyWNlzvw/Uz0HsRGEDYn9y+WGI/R9/\n9jFn+z//ye9Ame4Atfu738V7mF9VDDf6eE5J44zjRTTX+L6PhlM3LOqh6SnGALPuZ3bm8Ho3Mcay\nzXmMbaGhRK/mHj/O4LXn9/EazXQx1jiFCf/N0xCS3jG3betPKUYjJ6sQuxOo712o713Som+Rg9e4\nSTSNp8xBVhMaL3qoo1N5NFrUjvVyA01g/mT7EWf7dBWPpRkTXW2gUUykmK/4Phr0LBTde/9cDucC\nWR+1dTlG08lGgHXrzLvXZPYoXqNBu6DE8BrSDFminNtxUYAat3hpizKESZTHfXvKdMNm3Hpk1/Bg\nWfRnvGM4ju/CcXyXNIzjw7jmfkhE/oaIPGeMeXon9rdF5JPGmMfkprfYBRH5W/uuBSHjhRonaYb6\nJmmHGidphxonqWQY19xvy82VV5L8wcFXh5DRQ42TNEN9k7RDjZO0Q42TtHJHrrmEEEIIIYQQQsjd\nwgdRQgghhBBCCCEjZZgc0QPDWpHBwE2+tQGaAi1tNJ3tnPK4fLqGWeNejMm4lRwmvm8M3ETqCy9f\ngDIzhw9B7EoLE4cHyosS+UyAdbMDdzvCJOqZDNZ1PUKzgGoRE4xnAzdROIqxYt0umgl1c1hXM4tJ\nx9Vq8vjYFq0O1tVa7JPAw3OvlDD5uZQwdCplsUysnNM4iawn26HbPwN/AOXO3jjhbFfyaOr06Mlr\nEAsMtvuxGjohbK6Wne3/9/w7oUwyaV9EZHWAphNxiBdgUAwhljSxyHl43o/OLEFseRX1FtbxPMMF\n11yjFSlGXm3Ult9RLlLFZAw+E708JNhSXC1Q4hJnFSONGrZHruL2e7+KGjdKPcYF9b0L9e2SBn2/\niU3Uab2P5n/rPddwZFYx9nmscgVitQzeszIeNkKj486N3rBoZhLGitljTzEAClBvpRyau9SzbWf7\nUK4JZaIq6m2zg/O4bQ810p5LGLn0sf5eV9F9qJgOKW+pRoXkZ2Id/B7up2kwDjAYlfYWq2aQoxkk\njROO47twHHcZxzjOX0QJIYQQQgghhIwUPogSQgghhBBCCBkpfBAlhBBCCCGEEDJS+CBKCCGEEEII\nIWSkjNSsyPM8yRdcQ56+waTajaabMF8voKFOr9uF2FZjE2Lb25hsP5N3TQZMiAm7b7zwCsRquRLE\n7jt0BGLtFtbDxq4xQGzxnLIedsdMEU0S+oFiRmDc47Ua21AGrZBEMmU0GQgCrFux6O4dDjChuV/A\nBOYoxgzmOOkEIXo/nXtp2dk+PINmDaeOoKmUfOcZjI2IwIvkSME9F83oIpmkH89hovpyiMnxLzcP\nQ+zaFparz7v9bwxq/IevnIKYP4tmBB+5/w38zFYNYrF1z6EXo05ns2josTCHfd+uoAbzgau5zSYq\nOi7heGIyaCiQy6GJwdGiayLSDrEO7R5qfDBQvs9TzMKiLTQZk5ddHXSOYV2Pn1mGGPbIaKC+d6G+\nXdKg75sYsYm+Thq7iIhsdN3+yShuHY0I+7AxwJin6LdWcOc4Sf2JiPRC1GClhHOjY9UtiBUzaFZU\n8F3d+IoTSj1As6XFCmp81VfMHRMmjb0+1j9WtOUpxkfZLM5BkmY6kWLm1FI1rpi7KLqPOnjNSM8t\nN5jFerVHO9XeE47ju3AcdxnHOM5fRAkhhBBCCCGEjBQ+iBJCCCGEEEIIGSl8ECWEEEIIIYQQMlL4\nIEoIIYQQQgghZKSMNIM6DENZXrrhxHIlTGBeqLrJvUfm56BMv4vJyoFifDRTrGBFfPf5O1fFMr7y\niJ5TzITySnK19nhvE0YGXcEk5IyyY6GAicMmwn27264ZQdhGQ4FqBc2W8gX8TONhLJ9x29ZkMUG6\n08N6KbnQEsaYzI+1FZmruYnm8zMzUKacxaTscdIOs/L9pZNOrJpH84jDi66h1UeOYFr3aliGWC2L\nx3pobmXPes0ryfdnMyfw+Dk8/qEcJulrRAkTgOUeXlclHw0y5otYtzWDxgnNjmusFYV4vddqbYjN\nFFFdmjnIXN6thydYZqWLfRJGWA/NQGClhVrtHXKT/qtHsK2Pl9H8bFxQ37tQ34l9U6BvERGJRWzX\nPWetPe+rbDjbJ4obUCYwaOqhxRYLjT1jgxj7YaWH/VXO4NzoVHENYqHF47Uid76x1MP5WWiVeUoG\n7/3VPNZju+ceXzNgSpq93DwWXrelAK+1auCW8xQDqa0+mse0BqjdRheNHDcszqGijNse5Spej80Y\n+2mccBzfheN4Yt8xjOP8RZQQQgghhBBCyEjhgyghhBBCCCGEkJGy54OoMSZvjPmeMeYZY8wLxpi/\nuxM/bYz5rjHmdWPMPzPGTNY7koQMCTVO0g41TtIM9U3SDjVO0sowOaI9EfmotXbbGBOIyLeNMf+f\niPyPIvI5a+1XjDH/SEQ+LSK/ebsDeZ4nxaL7fn61jNdMJVEmm8N39dc38B3ubAZPxw/w+LF18wZs\nhLkM83XMBShk8FhBiPke2uP9duTWd1XJcR108ViVvFL/AZ67n8hTKFQxD8L6ykLRPraZ8bCcNW4s\nr/RJhKkdEhk81iDCd9qLJXynPU7ksATKu/D9Nr5rvw8OTOO+F8tcIpfgoSou9Pto8ZqzPZvZhjLf\naZ6BWE1bTDyH+UXJ/B8tH+g9C1cgdjSH7/nXfC2DFznfcnO5X1w+gvVS8iUWanju2kLkQWKBdFvE\n6yC5EL2IvtC8tnB2Ml/pUB7zILoRXi995RrqDjCWLSv1TSRRF7KYa7UV4rW2Dw5E49T3LtS3Sxr0\nLSIiRkQybvsdL6JuTmqg6qsAAAi/SURBVOVXnW0t9/NSD/0ttgZ4vjkPb57JmJZPmfHwM6sZzJ8r\n+zjfaEQ4R0j2xYWtWSjTCRWvDCWvU7GHEN9ztZrUvIhINoPH0nJQ8z7GColYQcn1G5ZBFq/RsITX\ndzLnsKLkxjbNgeSIcp6yA8fxXdIwju/5i6i9yZs9EOz8sSLyURH5vZ34l0Tk5/ddC0LGCDVO0g41\nTtIM9U3SDjVO0spQOaLGGN8Y87SILIvIN0TkDRHZtNa++dXVFRE5dm+qSMi9hxonaYcaJ2mG+iZp\nhxonaWSoB1FrbWStfUxEjovI+0XkkWE/wBjzGWPMWWPM2e3e/l+TIOReclAaDxvDvR5CyKjZr8ap\nbzINHNQYHjVxmQZCJgHOU0gauSPXXGvtpog8KSIfFJG6MebNF4yPi8jVt9jn89bax621j5dzzKEm\nk83dajyoYd4NIZPEnWqc+ibTxN2O4b6y3jYhkwTnKSRN7GlWZIxZEJHQWrtpjCmIyMdE5O/JzYvg\nr4nIV0TkUyLytb2O5XlGcgX3AigrJjWZRJL4Vge/obyyhcnKW5uYtDtfwsVqqzX3RuP38Hl8aQsX\ngC4WcxDLYS6xeMrC06HvPoT3Q/xGarOJ9bcDHDCKOaxHPtGu4WC4xOes8uWAtVgukzCCMooJke9j\nO3ZD/BW8rNS/nMdE537sJn37Bo9vFeOmO+UgNZ7xYpnNuQZKZwpoAlDxXUOJFzrHocyTl9EEoLmJ\nCygfPozXwunqurOdNHEQETl7AxeKni/jtVbLolazisnEVt/tw34Ph5fBGvbzsnIN1cpouFEruDFt\nMWZtAehaDus/UEwGShlXS9qx8j4aaax3ceJ6tIzGDFqsmUjwzynH1+p6pxyUxqnvXajvvWPTpm8R\nEdM3kr3qtv03Zx6CcqXcKWe71cN76fYqtp3pKvexPN6vvYLi/pcg7uJcQ3zsVz+Lx1du8xJ3XE37\nm4oBJEpXtvCWLpFyTvDTh1KHDaX+13LKfCajtFnCZMrzsEw0wPaPe0o7KoYyopxSslxTcM5ZvDSM\nL+jt4TxlF47jtz/WtI3jw1wdiyLyJWOMLzeHkd+11v4rY8yLIvIVY8z/JiI/FJEv7LsWhIwXapyk\nHWqcpBnqm6Qdapykkj0fRK21z4rIu5X4Obn5jjohUw01TtIONU7SDPVN0g41TtLK3b8TQwghhBBC\nCCGE3AF8ECWEEEIIIYQQMlKMZkxzzz7MmBURuSgi8yKyOrIPPnimvf4i038Ot6v/fdbahVFW5k2o\n8Ykh7fUfi8Zv0bdI+tt40klz/SdhDBdJdxtPA2mu/yRoPM3tOw1Me/1FDkDjI30Q/dGHGnPWWvv4\nyD/4gJj2+otM/zlMev0nvX57wfqPl2mo/zTU8Xaw/uNlGuo/DXW8Haz/eJn0+k96/faC9R8/B3EO\nfDWXEEIIIYQQQshI4YMoIYQQQgghhJCRMq4H0c+P6XMPimmvv8j0n8Ok13/S67cXrP94mYb6T0Md\nbwfrP16mof7TUMfbwfqPl0mv/6TXby9Y//Fz1+cwlhxRQgghhBBCCCE/vvDVXEIIIYQQQgghI4UP\nooQQQgghhBBCRsrIH0SNMR83xrxijHndGPPZUX/+nWKM+aIxZtkY8/wtsVljzDeMMa/t/D0zzjre\nDmPMCWPMk8aYF40xLxhjfmknPhXnYIzJG2O+Z4x5Zqf+f3cnftoY890dHf0zY0x23HV9E2p8tFDj\no2Xa9C0y3Rqfdn2LUOP3mmnWt8j0a3za9C1CjY8aavytGemDqDHGF5H/S0T+PRF5VEQ+aYx5dJR1\n2AdPiMjHE7HPisg3rbVnROSbO9uTykBEfsVa+6iIfEBE/tudNp+Wc+iJyEette8SkcdE5OPGmA+I\nyN8Tkc9Zax8UkQ0R+fQY6/gjqPGxQI2PiCnVt8h0a3za9S1Cjd9rnpDp1bfI9Gt8avQtQo2PCWr8\nLRj1L6LvF5HXrbXnrLV9EfmKiHxixHW4I6y13xKR9UT4EyLypZ1/f0lEfn6klboDrLXXrbVP7fy7\nKSIvicgxmZJzsDfZ3tkMdv5YEfmoiPzeTnyS6k+NjxhqfKRMnb5Fplvj065vEWr8XjPN+haZfo1P\nmb5FqPGRQ42/NaN+ED0mIpdv2b6yE5s2Dltrr+/8+4aIHB5nZYbFGHNKRN4tIt+VKToHY4xvjHla\nRJZF5Bsi8oaIbFprBztFJklH1PgYocbvOWnRt8gU6eNNplXfItT4GJgqfbzJtGp8ivQtQo2PFWrc\nhWZFd4m9uf7NxK+BY4wpi8hXReSXrbVbt/7fpJ+DtTay1j4mIsfl5jd5j4y5Sj9WTLo+3oQaJ/tl\n0vUhMt36FqHGx8k06ENkujVOfY+XSdfHm1DjyKgfRK+KyIlbto/vxKaNJWPMoojIzt/LY67PbTHG\nBHJT+F+21v7+TniqzkFExFq7KSJPisgHRaRujMns/Nck6YgaHwPU+MhIi75FpkgfadG3CDU+QqZK\nH2nR+BToW4QaHwvUuM6oH0S/LyJndlyWsiLyCyLy9RHX4SD4uoh8auffnxKRr42xLrfFGGNE5Asi\n8pK19jdu+a+pOAdjzIIxpr7z74KIfExuvlv/pIj8tZ1ik1R/anzEUOMjJS36FpkefUy1vkWo8TEx\nTfqYao1Pmb5FqPGRQ43fBmvtSP+IyM+JyKty893i/2nUn7+P+v6OiFwXkVBuvv/8aRGZk5vuVq+J\nyJ+IyOy463mb+n9Ybv7U/6yIPL3z5+em5RxE5J0i8sOd+j8vIv/LTvx+EfmeiLwuIv9cRHLjrust\ndabGR1t/any09Z0qfe/UeWo1Pu363jkHavze1ndq9b1T/6nW+LTpe6du1Pho60+Nv8Ufs3MgQggh\nhBBCCCFkJNCsiBBCCCGEEELISOGDKCGEEEIIIYSQkcIHUUIIIYQQQgghI4UPooQQQgghhBBCRgof\nRAkhhBBCCCGEjBQ+iBJCCCGEEEIIGSl8ECWEEEIIIYQQMlL+f+e1aSDDburIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1152x720 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTuRWucxLT-q",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}